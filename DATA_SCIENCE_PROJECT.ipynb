{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***IMPORT NECESSARY LIBRARIES***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "from dash import html, dcc, Input, Output\n",
    "import dash\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#to make sure all libraries are installed, run in your terminal -> pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***DATA ACQUISITION***</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading Data From csv file and converting non-numeric data to numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['school', 'sex', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
      "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
      "0       0    0   18        1        0        0     4     4     0     4  ...   \n",
      "1       0    0   17        1        0        1     1     1     0     2  ...   \n",
      "2       0    0   15        1        1        1     1     1     0     2  ...   \n",
      "3       0    0   15        1        0        1     4     2     1     3  ...   \n",
      "4       0    0   16        1        0        1     3     3     2     2  ...   \n",
      "\n",
      "   internet  romantic  famrel  freetime  goout  Dalc  Walc  health  absences  \\\n",
      "0         0         0       4         3      4     1     1       3         4   \n",
      "1         1         0       5         3      3     1     1       3         2   \n",
      "2         1         0       4         3      2     2     3       3         6   \n",
      "3         1         1       3         2      2     1     1       5         0   \n",
      "4         0         0       4         3      2     1     2       5         0   \n",
      "\n",
      "     average  \n",
      "0   7.333333  \n",
      "1  10.333333  \n",
      "2  12.333333  \n",
      "3  14.000000  \n",
      "4  12.333333  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "      <td>649.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.348228</td>\n",
       "      <td>0.409861</td>\n",
       "      <td>16.744222</td>\n",
       "      <td>0.696456</td>\n",
       "      <td>0.295840</td>\n",
       "      <td>0.876733</td>\n",
       "      <td>2.514638</td>\n",
       "      <td>2.306626</td>\n",
       "      <td>1.941448</td>\n",
       "      <td>2.224961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767334</td>\n",
       "      <td>0.368259</td>\n",
       "      <td>3.930663</td>\n",
       "      <td>3.180277</td>\n",
       "      <td>3.184900</td>\n",
       "      <td>1.502311</td>\n",
       "      <td>2.280431</td>\n",
       "      <td>3.536210</td>\n",
       "      <td>3.659476</td>\n",
       "      <td>11.625064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476776</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>1.218138</td>\n",
       "      <td>0.460143</td>\n",
       "      <td>0.456771</td>\n",
       "      <td>0.328996</td>\n",
       "      <td>1.134552</td>\n",
       "      <td>1.099931</td>\n",
       "      <td>1.248317</td>\n",
       "      <td>0.863487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422857</td>\n",
       "      <td>0.482704</td>\n",
       "      <td>0.955717</td>\n",
       "      <td>1.051093</td>\n",
       "      <td>1.175766</td>\n",
       "      <td>0.924834</td>\n",
       "      <td>1.284380</td>\n",
       "      <td>1.446259</td>\n",
       "      <td>4.640759</td>\n",
       "      <td>2.833360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>13.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>18.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           school         sex         age     address     famsize     Pstatus  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     0.348228    0.409861   16.744222    0.696456    0.295840    0.876733   \n",
       "std      0.476776    0.492187    1.218138    0.460143    0.456771    0.328996   \n",
       "min      0.000000    0.000000   15.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000   16.000000    0.000000    0.000000    1.000000   \n",
       "50%      0.000000    0.000000   17.000000    1.000000    0.000000    1.000000   \n",
       "75%      1.000000    1.000000   18.000000    1.000000    1.000000    1.000000   \n",
       "max      1.000000    1.000000   22.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             Medu        Fedu        Mjob        Fjob  ...    internet  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  ...  649.000000   \n",
       "mean     2.514638    2.306626    1.941448    2.224961  ...    0.767334   \n",
       "std      1.134552    1.099931    1.248317    0.863487  ...    0.422857   \n",
       "min      0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "25%      2.000000    1.000000    1.000000    2.000000  ...    1.000000   \n",
       "50%      2.000000    2.000000    2.000000    2.000000  ...    1.000000   \n",
       "75%      4.000000    3.000000    3.000000    3.000000  ...    1.000000   \n",
       "max      4.000000    4.000000    4.000000    4.000000  ...    1.000000   \n",
       "\n",
       "         romantic      famrel    freetime       goout        Dalc        Walc  \\\n",
       "count  649.000000  649.000000  649.000000  649.000000  649.000000  649.000000   \n",
       "mean     0.368259    3.930663    3.180277    3.184900    1.502311    2.280431   \n",
       "std      0.482704    0.955717    1.051093    1.175766    0.924834    1.284380   \n",
       "min      0.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "25%      0.000000    4.000000    3.000000    2.000000    1.000000    1.000000   \n",
       "50%      0.000000    4.000000    3.000000    3.000000    1.000000    2.000000   \n",
       "75%      1.000000    5.000000    4.000000    4.000000    2.000000    3.000000   \n",
       "max      1.000000    5.000000    5.000000    5.000000    5.000000    5.000000   \n",
       "\n",
       "           health    absences     average  \n",
       "count  649.000000  649.000000  649.000000  \n",
       "mean     3.536210    3.659476   11.625064  \n",
       "std      1.446259    4.640759    2.833360  \n",
       "min      1.000000    0.000000    1.333333  \n",
       "25%      2.000000    0.000000   10.000000  \n",
       "50%      4.000000    2.000000   11.666667  \n",
       "75%      5.000000    6.000000   13.333333  \n",
       "max      5.000000   32.000000   18.666667  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Data Acquisition\n",
    "df = pd.read_csv(\"student_data.csv\")\n",
    "\n",
    "#Detect non-numeric datatypes\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "print (non_numeric_columns)\n",
    "\n",
    "# Convert non-numeric columns into numerical values using Label Encoding\n",
    "label_encoders = LabelEncoder()\n",
    "for col in non_numeric_columns:\n",
    "    df[col] = label_encoders.fit_transform(df[col])\n",
    "\n",
    "\n",
    "df['average'] = df[['G1', 'G2', 'G3']].mean(axis=1)\n",
    "# step 2: Dropping the original G1, G2, G3 columns\n",
    "df = df.drop(columns=['G1', 'G2', 'G3'])\n",
    "# display the first few rows to verify the changes\n",
    "print(df.head())\n",
    "X_features = df.drop(columns=['average'])\n",
    "Target = df.iloc[:, -1]\n",
    "#Data Description\n",
    "#df.info()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***DATA WRANGLING***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQyl8-Q7AwWN",
    "outputId": "280f5f52-aa54-45b9-d686-8f027fdabe45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school        0\n",
      "sex           0\n",
      "age           0\n",
      "address       0\n",
      "famsize       0\n",
      "Pstatus       0\n",
      "Medu          0\n",
      "Fedu          0\n",
      "Mjob          0\n",
      "Fjob          0\n",
      "reason        0\n",
      "guardian      0\n",
      "traveltime    0\n",
      "studytime     0\n",
      "failures      0\n",
      "schoolsup     0\n",
      "famsup        0\n",
      "paid          0\n",
      "activities    0\n",
      "nursery       0\n",
      "higher        0\n",
      "internet      0\n",
      "romantic      0\n",
      "famrel        0\n",
      "freetime      0\n",
      "goout         0\n",
      "Dalc          0\n",
      "Walc          0\n",
      "health        0\n",
      "absences      0\n",
      "average       0\n",
      "dtype: int64\n",
      "\n",
      "***There are no missing/null values***\n",
      "\n",
      "     school  sex  age  address  famsize  Pstatus  Medu  Fedu  Mjob  Fjob  ...  \\\n",
      "0         0    0   18        1        0        0     4     4     0     4  ...   \n",
      "1         0    0   17        1        0        1     1     1     0     2  ...   \n",
      "2         0    0   15        1        1        1     1     1     0     2  ...   \n",
      "3         0    0   15        1        0        1     4     2     1     3  ...   \n",
      "4         0    0   16        1        0        1     3     3     2     2  ...   \n",
      "..      ...  ...  ...      ...      ...      ...   ...   ...   ...   ...  ...   \n",
      "644       1    0   19        0        0        1     2     3     3     2  ...   \n",
      "645       1    0   18        1        1        1     3     1     4     3  ...   \n",
      "646       1    0   18        1        0        1     1     1     2     2  ...   \n",
      "647       1    1   17        1        1        1     3     1     3     3  ...   \n",
      "648       1    1   18        0        1        1     3     2     3     2  ...   \n",
      "\n",
      "     internet  romantic  famrel  freetime  goout  Dalc  Walc  health  \\\n",
      "0           0         0       4         3      4     1     1       3   \n",
      "1           1         0       5         3      3     1     1       3   \n",
      "2           1         0       4         3      2     2     3       3   \n",
      "3           1         1       3         2      2     1     1       5   \n",
      "4           0         0       4         3      2     1     2       5   \n",
      "..        ...       ...     ...       ...    ...   ...   ...     ...   \n",
      "644         1         0       5         4      2     1     2       5   \n",
      "645         1         0       4         3      4     1     1       1   \n",
      "646         0         0       1         1      1     1     1       5   \n",
      "647         1         0       2         4      5     3     4       2   \n",
      "648         1         0       4         4      1     3     4       5   \n",
      "\n",
      "     absences    average  \n",
      "0           4   7.333333  \n",
      "1           2  10.333333  \n",
      "2           6  12.333333  \n",
      "3           0  14.000000  \n",
      "4           0  12.333333  \n",
      "..        ...        ...  \n",
      "644         4  10.333333  \n",
      "645         4  15.333333  \n",
      "646         6  10.666667  \n",
      "647         6  10.000000  \n",
      "648         4  10.666667  \n",
      "\n",
      "[649 rows x 31 columns]\n",
      "\n",
      "***There are no duplicates***\n",
      "\n",
      "***The data set is clean , we will use as it is***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Data Cleaning\n",
    "\n",
    "#Check for null values\n",
    "print(df.isnull().sum())\n",
    "print (\"\\n***There are no missing/null values***\\n\")\n",
    "\n",
    "\n",
    "# 2 Remove Duplicates\n",
    "non_duplicate = df[~df.duplicated(df.columns)]\n",
    "print (non_duplicate)\n",
    "print (\"\\n***There are no duplicates***\\n\")\n",
    "\n",
    "print (\"***The data set is clean , we will use as it is***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***CORRELATION MATRIX***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uazuPrAZDAX1",
    "outputId": "d6a93fc8-c296-4afd-fd0b-4e8ecadf5f0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.083050</td>\n",
       "      <td>0.087170</td>\n",
       "      <td>-0.354520</td>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.028120</td>\n",
       "      <td>-0.254787</td>\n",
       "      <td>-0.209806</td>\n",
       "      <td>-0.206829</td>\n",
       "      <td>-0.081872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.240486</td>\n",
       "      <td>0.072241</td>\n",
       "      <td>-0.031597</td>\n",
       "      <td>0.034666</td>\n",
       "      <td>0.044632</td>\n",
       "      <td>0.047169</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>-0.058599</td>\n",
       "      <td>-0.163933</td>\n",
       "      <td>-0.295035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-0.083050</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043662</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>0.098205</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.119127</td>\n",
       "      <td>0.083913</td>\n",
       "      <td>0.149635</td>\n",
       "      <td>0.080466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065911</td>\n",
       "      <td>-0.110144</td>\n",
       "      <td>0.083473</td>\n",
       "      <td>0.146305</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.282696</td>\n",
       "      <td>0.320785</td>\n",
       "      <td>0.139547</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>-0.118333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.087170</td>\n",
       "      <td>-0.043662</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.025848</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>-0.107832</td>\n",
       "      <td>-0.121050</td>\n",
       "      <td>-0.071770</td>\n",
       "      <td>-0.050846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.178810</td>\n",
       "      <td>-0.020559</td>\n",
       "      <td>-0.004910</td>\n",
       "      <td>0.112805</td>\n",
       "      <td>0.134768</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>-0.008750</td>\n",
       "      <td>0.149998</td>\n",
       "      <td>-0.133499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>-0.354520</td>\n",
       "      <td>0.025503</td>\n",
       "      <td>-0.025848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>-0.094635</td>\n",
       "      <td>0.190320</td>\n",
       "      <td>0.141493</td>\n",
       "      <td>0.159761</td>\n",
       "      <td>-0.006535</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175794</td>\n",
       "      <td>-0.030939</td>\n",
       "      <td>-0.033897</td>\n",
       "      <td>-0.036647</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>-0.047304</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.167455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.022252</td>\n",
       "      <td>0.098205</td>\n",
       "      <td>-0.002470</td>\n",
       "      <td>0.046113</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.239608</td>\n",
       "      <td>-0.014325</td>\n",
       "      <td>-0.039538</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>-0.059443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>-0.032936</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>-0.021257</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.060482</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>0.045694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>0.028120</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>-0.005631</td>\n",
       "      <td>-0.094635</td>\n",
       "      <td>-0.239608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.057174</td>\n",
       "      <td>-0.031856</td>\n",
       "      <td>-0.028874</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059754</td>\n",
       "      <td>-0.053828</td>\n",
       "      <td>0.051303</td>\n",
       "      <td>0.037585</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>0.070976</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>-0.117492</td>\n",
       "      <td>0.011045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>-0.254787</td>\n",
       "      <td>0.119127</td>\n",
       "      <td>-0.107832</td>\n",
       "      <td>0.190320</td>\n",
       "      <td>-0.014325</td>\n",
       "      <td>-0.057174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.647477</td>\n",
       "      <td>0.459337</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266052</td>\n",
       "      <td>-0.030992</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>-0.019686</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>-0.019766</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>0.265905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>-0.209806</td>\n",
       "      <td>0.083913</td>\n",
       "      <td>-0.121050</td>\n",
       "      <td>0.141493</td>\n",
       "      <td>-0.039538</td>\n",
       "      <td>-0.031856</td>\n",
       "      <td>0.647477</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.290703</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183483</td>\n",
       "      <td>-0.067675</td>\n",
       "      <td>0.020256</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.044910</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.227918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob</th>\n",
       "      <td>-0.206829</td>\n",
       "      <td>0.149635</td>\n",
       "      <td>-0.071770</td>\n",
       "      <td>0.159761</td>\n",
       "      <td>0.019600</td>\n",
       "      <td>-0.028874</td>\n",
       "      <td>0.459337</td>\n",
       "      <td>0.290703</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260658</td>\n",
       "      <td>-0.074286</td>\n",
       "      <td>0.025049</td>\n",
       "      <td>0.053927</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.081525</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>0.167727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob</th>\n",
       "      <td>-0.081872</td>\n",
       "      <td>0.080466</td>\n",
       "      <td>-0.050846</td>\n",
       "      <td>-0.006535</td>\n",
       "      <td>-0.059443</td>\n",
       "      <td>0.054306</td>\n",
       "      <td>0.152582</td>\n",
       "      <td>0.211604</td>\n",
       "      <td>0.202651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>-0.002835</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>-0.037952</td>\n",
       "      <td>-0.031913</td>\n",
       "      <td>0.055389</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>-0.025069</td>\n",
       "      <td>-0.047477</td>\n",
       "      <td>0.085200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason</th>\n",
       "      <td>-0.109754</td>\n",
       "      <td>0.010732</td>\n",
       "      <td>-0.025855</td>\n",
       "      <td>-0.002367</td>\n",
       "      <td>0.032321</td>\n",
       "      <td>-0.031486</td>\n",
       "      <td>0.132855</td>\n",
       "      <td>0.080760</td>\n",
       "      <td>0.059397</td>\n",
       "      <td>0.042846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110168</td>\n",
       "      <td>-0.050643</td>\n",
       "      <td>0.036657</td>\n",
       "      <td>-0.047001</td>\n",
       "      <td>-0.008255</td>\n",
       "      <td>-0.010735</td>\n",
       "      <td>0.010612</td>\n",
       "      <td>-0.121866</td>\n",
       "      <td>0.015861</td>\n",
       "      <td>0.151711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian</th>\n",
       "      <td>-0.062333</td>\n",
       "      <td>-0.036811</td>\n",
       "      <td>0.266830</td>\n",
       "      <td>-0.019359</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>-0.169904</td>\n",
       "      <td>-0.014044</td>\n",
       "      <td>-0.101764</td>\n",
       "      <td>0.008196</td>\n",
       "      <td>-0.075056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000412</td>\n",
       "      <td>0.106190</td>\n",
       "      <td>-0.052143</td>\n",
       "      <td>0.051442</td>\n",
       "      <td>0.054880</td>\n",
       "      <td>0.023330</td>\n",
       "      <td>-0.008312</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.150426</td>\n",
       "      <td>-0.103150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime</th>\n",
       "      <td>0.252936</td>\n",
       "      <td>0.040880</td>\n",
       "      <td>0.034490</td>\n",
       "      <td>-0.344902</td>\n",
       "      <td>0.012794</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>-0.265079</td>\n",
       "      <td>-0.208288</td>\n",
       "      <td>-0.164126</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190826</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>-0.009521</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.057454</td>\n",
       "      <td>0.092824</td>\n",
       "      <td>0.057007</td>\n",
       "      <td>-0.048261</td>\n",
       "      <td>-0.008149</td>\n",
       "      <td>-0.151066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime</th>\n",
       "      <td>-0.137857</td>\n",
       "      <td>-0.206214</td>\n",
       "      <td>-0.008415</td>\n",
       "      <td>0.062023</td>\n",
       "      <td>-0.010945</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>0.097006</td>\n",
       "      <td>0.050400</td>\n",
       "      <td>0.057176</td>\n",
       "      <td>-0.019125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037529</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>-0.004127</td>\n",
       "      <td>-0.068829</td>\n",
       "      <td>-0.075442</td>\n",
       "      <td>-0.137585</td>\n",
       "      <td>-0.214925</td>\n",
       "      <td>-0.056433</td>\n",
       "      <td>-0.118389</td>\n",
       "      <td>0.261630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures</th>\n",
       "      <td>0.113788</td>\n",
       "      <td>0.073888</td>\n",
       "      <td>0.319968</td>\n",
       "      <td>-0.063824</td>\n",
       "      <td>-0.066068</td>\n",
       "      <td>-0.009881</td>\n",
       "      <td>-0.172210</td>\n",
       "      <td>-0.165915</td>\n",
       "      <td>-0.117882</td>\n",
       "      <td>-0.055415</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095330</td>\n",
       "      <td>0.069901</td>\n",
       "      <td>-0.062645</td>\n",
       "      <td>0.108995</td>\n",
       "      <td>0.045078</td>\n",
       "      <td>0.105949</td>\n",
       "      <td>0.082266</td>\n",
       "      <td>0.035588</td>\n",
       "      <td>0.122779</td>\n",
       "      <td>-0.405815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup</th>\n",
       "      <td>-0.123340</td>\n",
       "      <td>-0.111202</td>\n",
       "      <td>-0.167841</td>\n",
       "      <td>0.017956</td>\n",
       "      <td>-0.056405</td>\n",
       "      <td>-0.009456</td>\n",
       "      <td>-0.022168</td>\n",
       "      <td>0.023572</td>\n",
       "      <td>0.007992</td>\n",
       "      <td>-0.013396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025942</td>\n",
       "      <td>-0.094310</td>\n",
       "      <td>-0.012038</td>\n",
       "      <td>-0.015611</td>\n",
       "      <td>-0.058124</td>\n",
       "      <td>-0.028076</td>\n",
       "      <td>-0.098275</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>-0.059503</td>\n",
       "      <td>-0.067830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup</th>\n",
       "      <td>-0.063720</td>\n",
       "      <td>-0.129467</td>\n",
       "      <td>-0.101894</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>-0.039819</td>\n",
       "      <td>0.010203</td>\n",
       "      <td>0.120491</td>\n",
       "      <td>0.135191</td>\n",
       "      <td>0.038817</td>\n",
       "      <td>-0.038630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071891</td>\n",
       "      <td>-0.023398</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>-0.016844</td>\n",
       "      <td>-0.065605</td>\n",
       "      <td>0.018803</td>\n",
       "      <td>0.041980</td>\n",
       "      <td>0.047932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid</th>\n",
       "      <td>-0.007905</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>-0.005458</td>\n",
       "      <td>-0.030483</td>\n",
       "      <td>-0.050253</td>\n",
       "      <td>0.015923</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>0.094628</td>\n",
       "      <td>0.011869</td>\n",
       "      <td>-0.020841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031823</td>\n",
       "      <td>-0.018309</td>\n",
       "      <td>0.031937</td>\n",
       "      <td>-0.049574</td>\n",
       "      <td>-0.006683</td>\n",
       "      <td>0.051986</td>\n",
       "      <td>0.035682</td>\n",
       "      <td>0.063203</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>-0.052771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities</th>\n",
       "      <td>-0.088604</td>\n",
       "      <td>0.124707</td>\n",
       "      <td>-0.054279</td>\n",
       "      <td>-0.009278</td>\n",
       "      <td>-0.014790</td>\n",
       "      <td>0.101555</td>\n",
       "      <td>0.119354</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.099962</td>\n",
       "      <td>0.018356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082375</td>\n",
       "      <td>0.057517</td>\n",
       "      <td>0.057597</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>0.088582</td>\n",
       "      <td>0.022592</td>\n",
       "      <td>0.032824</td>\n",
       "      <td>0.013001</td>\n",
       "      <td>-0.015115</td>\n",
       "      <td>0.071621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>0.004659</td>\n",
       "      <td>-0.043603</td>\n",
       "      <td>-0.021441</td>\n",
       "      <td>0.018077</td>\n",
       "      <td>0.100686</td>\n",
       "      <td>-0.032724</td>\n",
       "      <td>0.125951</td>\n",
       "      <td>0.074863</td>\n",
       "      <td>0.041927</td>\n",
       "      <td>-0.045800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007159</td>\n",
       "      <td>-0.022984</td>\n",
       "      <td>0.041055</td>\n",
       "      <td>-0.007096</td>\n",
       "      <td>0.018679</td>\n",
       "      <td>-0.078376</td>\n",
       "      <td>-0.075748</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>-0.040574</td>\n",
       "      <td>0.034661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher</th>\n",
       "      <td>-0.136112</td>\n",
       "      <td>-0.058134</td>\n",
       "      <td>-0.265497</td>\n",
       "      <td>0.076706</td>\n",
       "      <td>0.004523</td>\n",
       "      <td>0.022726</td>\n",
       "      <td>0.213896</td>\n",
       "      <td>0.191735</td>\n",
       "      <td>0.148116</td>\n",
       "      <td>0.089929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070345</td>\n",
       "      <td>-0.099389</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>-0.102618</td>\n",
       "      <td>-0.069105</td>\n",
       "      <td>-0.131663</td>\n",
       "      <td>-0.084327</td>\n",
       "      <td>0.017290</td>\n",
       "      <td>-0.129891</td>\n",
       "      <td>0.352762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>-0.240486</td>\n",
       "      <td>0.065911</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.175794</td>\n",
       "      <td>0.013357</td>\n",
       "      <td>0.059754</td>\n",
       "      <td>0.266052</td>\n",
       "      <td>0.183483</td>\n",
       "      <td>0.260658</td>\n",
       "      <td>0.088625</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>0.082214</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>0.092869</td>\n",
       "      <td>0.042811</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>-0.022792</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>0.152914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic</th>\n",
       "      <td>0.072241</td>\n",
       "      <td>-0.110144</td>\n",
       "      <td>0.178810</td>\n",
       "      <td>-0.030939</td>\n",
       "      <td>-0.032936</td>\n",
       "      <td>-0.053828</td>\n",
       "      <td>-0.030992</td>\n",
       "      <td>-0.067675</td>\n",
       "      <td>-0.074286</td>\n",
       "      <td>-0.002835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044920</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>0.062042</td>\n",
       "      <td>-0.019971</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>0.079489</td>\n",
       "      <td>-0.092213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel</th>\n",
       "      <td>-0.031597</td>\n",
       "      <td>0.083473</td>\n",
       "      <td>-0.020559</td>\n",
       "      <td>-0.033897</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.051303</td>\n",
       "      <td>0.024421</td>\n",
       "      <td>0.020256</td>\n",
       "      <td>0.025049</td>\n",
       "      <td>0.039500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082214</td>\n",
       "      <td>-0.044920</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129216</td>\n",
       "      <td>0.089707</td>\n",
       "      <td>-0.075767</td>\n",
       "      <td>-0.093511</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>-0.089534</td>\n",
       "      <td>0.070550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime</th>\n",
       "      <td>0.034666</td>\n",
       "      <td>0.146305</td>\n",
       "      <td>-0.004910</td>\n",
       "      <td>-0.036647</td>\n",
       "      <td>-0.021257</td>\n",
       "      <td>0.037585</td>\n",
       "      <td>-0.019686</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.053927</td>\n",
       "      <td>-0.037952</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063268</td>\n",
       "      <td>0.027112</td>\n",
       "      <td>0.129216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346352</td>\n",
       "      <td>0.109904</td>\n",
       "      <td>0.120244</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>-0.113723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout</th>\n",
       "      <td>0.044632</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.112805</td>\n",
       "      <td>0.015475</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>-0.031913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092869</td>\n",
       "      <td>-0.000520</td>\n",
       "      <td>0.089707</td>\n",
       "      <td>0.346352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.245126</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>-0.084467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dalc</th>\n",
       "      <td>0.047169</td>\n",
       "      <td>0.282696</td>\n",
       "      <td>0.134768</td>\n",
       "      <td>-0.047304</td>\n",
       "      <td>0.060482</td>\n",
       "      <td>0.041513</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.049576</td>\n",
       "      <td>0.055389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042811</td>\n",
       "      <td>0.062042</td>\n",
       "      <td>-0.075767</td>\n",
       "      <td>0.109904</td>\n",
       "      <td>0.245126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616561</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>0.172952</td>\n",
       "      <td>-0.205792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Walc</th>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.320785</td>\n",
       "      <td>0.086357</td>\n",
       "      <td>-0.012416</td>\n",
       "      <td>0.081958</td>\n",
       "      <td>0.070976</td>\n",
       "      <td>-0.019766</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.044607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>-0.019971</td>\n",
       "      <td>-0.093511</td>\n",
       "      <td>0.120244</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>0.616561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114988</td>\n",
       "      <td>0.156373</td>\n",
       "      <td>-0.173906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health</th>\n",
       "      <td>-0.058599</td>\n",
       "      <td>0.139547</td>\n",
       "      <td>-0.008750</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.012638</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.044910</td>\n",
       "      <td>0.081525</td>\n",
       "      <td>-0.025069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022792</td>\n",
       "      <td>-0.018025</td>\n",
       "      <td>0.109559</td>\n",
       "      <td>0.084526</td>\n",
       "      <td>-0.015741</td>\n",
       "      <td>0.059067</td>\n",
       "      <td>0.114988</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030235</td>\n",
       "      <td>-0.082420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences</th>\n",
       "      <td>-0.163933</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.149998</td>\n",
       "      <td>0.073653</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>-0.117492</td>\n",
       "      <td>-0.008577</td>\n",
       "      <td>0.029859</td>\n",
       "      <td>0.028519</td>\n",
       "      <td>-0.047477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>0.079489</td>\n",
       "      <td>-0.089534</td>\n",
       "      <td>-0.018716</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>0.172952</td>\n",
       "      <td>0.156373</td>\n",
       "      <td>-0.030235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.125015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average</th>\n",
       "      <td>-0.295035</td>\n",
       "      <td>-0.118333</td>\n",
       "      <td>-0.133499</td>\n",
       "      <td>0.167455</td>\n",
       "      <td>0.045694</td>\n",
       "      <td>0.011045</td>\n",
       "      <td>0.265905</td>\n",
       "      <td>0.227918</td>\n",
       "      <td>0.167727</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152914</td>\n",
       "      <td>-0.092213</td>\n",
       "      <td>0.070550</td>\n",
       "      <td>-0.113723</td>\n",
       "      <td>-0.084467</td>\n",
       "      <td>-0.205792</td>\n",
       "      <td>-0.173906</td>\n",
       "      <td>-0.082420</td>\n",
       "      <td>-0.125015</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              school       sex       age   address   famsize   Pstatus  \\\n",
       "school      1.000000 -0.083050  0.087170 -0.354520  0.022252  0.028120   \n",
       "sex        -0.083050  1.000000 -0.043662  0.025503  0.098205  0.064700   \n",
       "age         0.087170 -0.043662  1.000000 -0.025848 -0.002470 -0.005631   \n",
       "address    -0.354520  0.025503 -0.025848  1.000000  0.046113 -0.094635   \n",
       "famsize     0.022252  0.098205 -0.002470  0.046113  1.000000 -0.239608   \n",
       "Pstatus     0.028120  0.064700 -0.005631 -0.094635 -0.239608  1.000000   \n",
       "Medu       -0.254787  0.119127 -0.107832  0.190320 -0.014325 -0.057174   \n",
       "Fedu       -0.209806  0.083913 -0.121050  0.141493 -0.039538 -0.031856   \n",
       "Mjob       -0.206829  0.149635 -0.071770  0.159761  0.019600 -0.028874   \n",
       "Fjob       -0.081872  0.080466 -0.050846 -0.006535 -0.059443  0.054306   \n",
       "reason     -0.109754  0.010732 -0.025855 -0.002367  0.032321 -0.031486   \n",
       "guardian   -0.062333 -0.036811  0.266830 -0.019359  0.000872 -0.169904   \n",
       "traveltime  0.252936  0.040880  0.034490 -0.344902  0.012794  0.040633   \n",
       "studytime  -0.137857 -0.206214 -0.008415  0.062023 -0.010945 -0.008748   \n",
       "failures    0.113788  0.073888  0.319968 -0.063824 -0.066068 -0.009881   \n",
       "schoolsup  -0.123340 -0.111202 -0.167841  0.017956 -0.056405 -0.009456   \n",
       "famsup     -0.063720 -0.129467 -0.101894  0.005577 -0.039819  0.010203   \n",
       "paid       -0.007905  0.079300 -0.005458 -0.030483 -0.050253  0.015923   \n",
       "activities -0.088604  0.124707 -0.054279 -0.009278 -0.014790  0.101555   \n",
       "nursery     0.004659 -0.043603 -0.021441  0.018077  0.100686 -0.032724   \n",
       "higher     -0.136112 -0.058134 -0.265497  0.076706  0.004523  0.022726   \n",
       "internet   -0.240486  0.065911  0.013115  0.175794  0.013357  0.059754   \n",
       "romantic    0.072241 -0.110144  0.178810 -0.030939 -0.032936 -0.053828   \n",
       "famrel     -0.031597  0.083473 -0.020559 -0.033897  0.004641  0.051303   \n",
       "freetime    0.034666  0.146305 -0.004910 -0.036647 -0.021257  0.037585   \n",
       "goout       0.044632  0.058178  0.112805  0.015475 -0.004312  0.031086   \n",
       "Dalc        0.047169  0.282696  0.134768 -0.047304  0.060482  0.041513   \n",
       "Walc        0.014169  0.320785  0.086357 -0.012416  0.081958  0.070976   \n",
       "health     -0.058599  0.139547 -0.008750  0.003787  0.002448  0.012638   \n",
       "absences   -0.163933  0.021336  0.149998  0.073653  0.004645 -0.117492   \n",
       "average    -0.295035 -0.118333 -0.133499  0.167455  0.045694  0.011045   \n",
       "\n",
       "                Medu      Fedu      Mjob      Fjob  ...  internet  romantic  \\\n",
       "school     -0.254787 -0.209806 -0.206829 -0.081872  ... -0.240486  0.072241   \n",
       "sex         0.119127  0.083913  0.149635  0.080466  ...  0.065911 -0.110144   \n",
       "age        -0.107832 -0.121050 -0.071770 -0.050846  ...  0.013115  0.178810   \n",
       "address     0.190320  0.141493  0.159761 -0.006535  ...  0.175794 -0.030939   \n",
       "famsize    -0.014325 -0.039538  0.019600 -0.059443  ...  0.013357 -0.032936   \n",
       "Pstatus    -0.057174 -0.031856 -0.028874  0.054306  ...  0.059754 -0.053828   \n",
       "Medu        1.000000  0.647477  0.459337  0.152582  ...  0.266052 -0.030992   \n",
       "Fedu        0.647477  1.000000  0.290703  0.211604  ...  0.183483 -0.067675   \n",
       "Mjob        0.459337  0.290703  1.000000  0.202651  ...  0.260658 -0.074286   \n",
       "Fjob        0.152582  0.211604  0.202651  1.000000  ...  0.088625 -0.002835   \n",
       "reason      0.132855  0.080760  0.059397  0.042846  ...  0.110168 -0.050643   \n",
       "guardian   -0.014044 -0.101764  0.008196 -0.075056  ... -0.000412  0.106190   \n",
       "traveltime -0.265079 -0.208288 -0.164126  0.004749  ... -0.190826  0.004751   \n",
       "studytime   0.097006  0.050400  0.057176 -0.019125  ...  0.037529  0.033036   \n",
       "failures   -0.172210 -0.165915 -0.117882 -0.055415  ... -0.095330  0.069901   \n",
       "schoolsup  -0.022168  0.023572  0.007992 -0.013396  ... -0.025942 -0.094310   \n",
       "famsup      0.120491  0.135191  0.038817 -0.038630  ...  0.071891 -0.023398   \n",
       "paid        0.113973  0.094628  0.011869 -0.020841  ...  0.031823 -0.018309   \n",
       "activities  0.119354  0.079700  0.099962  0.018356  ...  0.082375  0.057517   \n",
       "nursery     0.125951  0.074863  0.041927 -0.045800  ... -0.007159 -0.022984   \n",
       "higher      0.213896  0.191735  0.148116  0.089929  ...  0.070345 -0.099389   \n",
       "internet    0.266052  0.183483  0.260658  0.088625  ...  1.000000  0.034832   \n",
       "romantic   -0.030992 -0.067675 -0.074286 -0.002835  ...  0.034832  1.000000   \n",
       "famrel      0.024421  0.020256  0.025049  0.039500  ...  0.082214 -0.044920   \n",
       "freetime   -0.019686  0.006841  0.053927 -0.037952  ...  0.063268  0.027112   \n",
       "goout       0.009536  0.027690  0.003182 -0.031913  ...  0.092869 -0.000520   \n",
       "Dalc       -0.007018  0.000061  0.049576  0.055389  ...  0.042811  0.062042   \n",
       "Walc       -0.019766  0.038445  0.025657  0.044607  ...  0.060651 -0.019971   \n",
       "health      0.004614  0.044910  0.081525 -0.025069  ... -0.022792 -0.018025   \n",
       "absences   -0.008577  0.029859  0.028519 -0.047477  ...  0.067301  0.079489   \n",
       "average     0.265905  0.227918  0.167727  0.085200  ...  0.152914 -0.092213   \n",
       "\n",
       "              famrel  freetime     goout      Dalc      Walc    health  \\\n",
       "school     -0.031597  0.034666  0.044632  0.047169  0.014169 -0.058599   \n",
       "sex         0.083473  0.146305  0.058178  0.282696  0.320785  0.139547   \n",
       "age        -0.020559 -0.004910  0.112805  0.134768  0.086357 -0.008750   \n",
       "address    -0.033897 -0.036647  0.015475 -0.047304 -0.012416  0.003787   \n",
       "famsize     0.004641 -0.021257 -0.004312  0.060482  0.081958  0.002448   \n",
       "Pstatus     0.051303  0.037585  0.031086  0.041513  0.070976  0.012638   \n",
       "Medu        0.024421 -0.019686  0.009536 -0.007018 -0.019766  0.004614   \n",
       "Fedu        0.020256  0.006841  0.027690  0.000061  0.038445  0.044910   \n",
       "Mjob        0.025049  0.053927  0.003182  0.049576  0.025657  0.081525   \n",
       "Fjob        0.039500 -0.037952 -0.031913  0.055389  0.044607 -0.025069   \n",
       "reason      0.036657 -0.047001 -0.008255 -0.010735  0.010612 -0.121866   \n",
       "guardian   -0.052143  0.051442  0.054880  0.023330 -0.008312  0.016556   \n",
       "traveltime -0.009521  0.000937  0.057454  0.092824  0.057007 -0.048261   \n",
       "studytime  -0.004127 -0.068829 -0.075442 -0.137585 -0.214925 -0.056433   \n",
       "failures   -0.062645  0.108995  0.045078  0.105949  0.082266  0.035588   \n",
       "schoolsup  -0.012038 -0.015611 -0.058124 -0.028076 -0.098275  0.022760   \n",
       "famsup      0.015228  0.003764  0.017262 -0.016844 -0.065605  0.018803   \n",
       "paid        0.031937 -0.049574 -0.006683  0.051986  0.035682  0.063203   \n",
       "activities  0.057597  0.150329  0.088582  0.022592  0.032824  0.013001   \n",
       "nursery     0.041055 -0.007096  0.018679 -0.078376 -0.075748  0.001701   \n",
       "higher      0.048239 -0.102618 -0.069105 -0.131663 -0.084327  0.017290   \n",
       "internet    0.082214  0.063268  0.092869  0.042811  0.060651 -0.022792   \n",
       "romantic   -0.044920  0.027112 -0.000520  0.062042 -0.019971 -0.018025   \n",
       "famrel      1.000000  0.129216  0.089707 -0.075767 -0.093511  0.109559   \n",
       "freetime    0.129216  1.000000  0.346352  0.109904  0.120244  0.084526   \n",
       "goout       0.089707  0.346352  1.000000  0.245126  0.388680 -0.015741   \n",
       "Dalc       -0.075767  0.109904  0.245126  1.000000  0.616561  0.059067   \n",
       "Walc       -0.093511  0.120244  0.388680  0.616561  1.000000  0.114988   \n",
       "health      0.109559  0.084526 -0.015741  0.059067  0.114988  1.000000   \n",
       "absences   -0.089534 -0.018716  0.085374  0.172952  0.156373 -0.030235   \n",
       "average     0.070550 -0.113723 -0.084467 -0.205792 -0.173906 -0.082420   \n",
       "\n",
       "            absences   average  \n",
       "school     -0.163933 -0.295035  \n",
       "sex         0.021336 -0.118333  \n",
       "age         0.149998 -0.133499  \n",
       "address     0.073653  0.167455  \n",
       "famsize     0.004645  0.045694  \n",
       "Pstatus    -0.117492  0.011045  \n",
       "Medu       -0.008577  0.265905  \n",
       "Fedu        0.029859  0.227918  \n",
       "Mjob        0.028519  0.167727  \n",
       "Fjob       -0.047477  0.085200  \n",
       "reason      0.015861  0.151711  \n",
       "guardian    0.150426 -0.103150  \n",
       "traveltime -0.008149 -0.151066  \n",
       "studytime  -0.118389  0.261630  \n",
       "failures    0.122779 -0.405815  \n",
       "schoolsup  -0.059503 -0.067830  \n",
       "famsup      0.041980  0.047932  \n",
       "paid       -0.035959 -0.052771  \n",
       "activities -0.015115  0.071621  \n",
       "nursery    -0.040574  0.034661  \n",
       "higher     -0.129891  0.352762  \n",
       "internet    0.067301  0.152914  \n",
       "romantic    0.079489 -0.092213  \n",
       "famrel     -0.089534  0.070550  \n",
       "freetime   -0.018716 -0.113723  \n",
       "goout       0.085374 -0.084467  \n",
       "Dalc        0.172952 -0.205792  \n",
       "Walc        0.156373 -0.173906  \n",
       "health     -0.030235 -0.082420  \n",
       "absences    1.000000 -0.125015  \n",
       "average    -0.125015  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Finding correlation matrix of all variables\n",
    "correlation_matrix = df.corr()                       \n",
    "\n",
    "print(\"Correlation Matrix:\")\n",
    "\n",
    "plt.matshow(correlation_matrix)\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the contributing Dataset according to Correlation Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features contributing to our target according to the Correlation matrix: ['school', 'Medu', 'Fedu', 'studytime', 'failures', 'higher', 'Dalc']\n"
     ]
    }
   ],
   "source": [
    "#Deciding which features attribute to our Target \"average\"\n",
    "average_Corr = correlation_matrix.columns[-1]\n",
    "\n",
    "Correlation_Relevant = []\n",
    "for feature in correlation_matrix.columns[:-1]:  # Exclude the last variable\n",
    "    if abs(correlation_matrix.loc[feature,average_Corr]) > 0.2:\n",
    "        Correlation_Relevant.append(feature)\n",
    "        \n",
    "print(\"Features contributing to our target according to the Correlation matrix:\", Correlation_Relevant)\n",
    "Relevant_DataSet_corr =df[Correlation_Relevant]\n",
    "Relevant_DataSet_corr['average']=Target\n",
    "#Our New DataSet \"Relevant_DataSet\"\n",
    "#print(Relevant_DataSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***Linear Regression***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating r2 adjusted functionn\n",
    "def adj_r2(X, y, model):\n",
    "        r2 = model.score(X, y)\n",
    "        n = X.shape[0]\n",
    "        p = X.shape[1]\n",
    "        adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "        return adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the standard error (SE)\n",
    "def calculate_standard_error(Y_target, Y_predicted, X_test, feature_variables):\n",
    "    N = len(Y_target)\n",
    "    residuals = Y_target - Y_predicted\n",
    "    SSE = np.sum(residuals**2)\n",
    "        \n",
    "    feature_avg = np.mean(X_test, axis=0)\n",
    "    SST = np.sum((X_test - feature_avg)**2, axis=0)\n",
    "        \n",
    "    SE = np.sqrt(SSE / (N - 2)) / np.sqrt(np.sum(SST))\n",
    "    return SE\n",
    "    \n",
    "\n",
    "def linear_model_creator(df, feature_variables, target_variable, test_size=0.2, normalize=False):\n",
    "    \n",
    "    # extracting the wanted features (X) and target variable (Y)\n",
    "    X = np.array(df[feature_variables])\n",
    "    Y = np.array(df[target_variable]).reshape(-1, 1)  # reshaping Y to 2D array for scaling\n",
    "\n",
    "    # optionally normalize the data\n",
    "    if normalize:\n",
    "        scaler_X = StandardScaler()\n",
    "        scaler_Y = StandardScaler()\n",
    "        X = scaler_X.fit_transform(X)\n",
    "        Y = scaler_Y.fit_transform(Y)\n",
    "   \n",
    "    # dividing the data into training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=0)\n",
    "       \n",
    "    # creating the Linear model\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, Y_train)\n",
    "\n",
    "    # creating predictions with the model\n",
    "    predictions = lm.predict(X_test)\n",
    "   \n",
    "    # unnormalize the predictions if data was normalized\n",
    "    if normalize:\n",
    "        predictions = scaler_Y.inverse_transform(predictions)\n",
    "        Y_test = scaler_Y.inverse_transform(Y_test)\n",
    "   \n",
    "    # creating the DataFrame with the used features, the target variable, and the predicted data\n",
    "    dictionary = {}\n",
    "    for feature in feature_variables:\n",
    "        dictionary[feature] = X_test[:, feature_variables.index(feature)]\n",
    "\n",
    "    lm_results = pd.DataFrame.from_dict(dictionary)\n",
    "    lm_results[\"Y_target\"] = Y_test.flatten()  # flattening Y_test to 1D array\n",
    "    lm_results[\"Y_predicted\"] = predictions.flatten()  # flattening predictions to 1D array\n",
    "   \n",
    "    # plotting the actual vs predicted values\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(lm_results[\"Y_target\"], lm_results[\"Y_predicted\"], color='blue')\n",
    "    plt.title(f'Actual vs Predicted')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    # evaluating the model\n",
    "    print(\"Target:\", target_variable)\n",
    "    print(\"Features:\", feature_variables)\n",
    "    print(\"The accuracy (R²) of the Model train is:\", lm.score(X_train, Y_train))\n",
    "    print(\"The accuracy (R²) of the Model test is:\", lm.score(X_test, Y_test))\n",
    "    print('The accuracy (MSE) of the train Model is: %.2f' % mean_squared_error(Y_train, lm.predict(X_train)))\n",
    "    print('The accuracy (MSE) of the test Model is: %.2f' % mean_squared_error(Y_test, predictions))\n",
    "    print(\"The intercept (alpha) is:\", lm.intercept_)\n",
    "    print(\"The coefficients (betas) are:\", lm.coef_)\n",
    "    \n",
    "    # calculating and printing the standard error (SE)\n",
    "    SE = calculate_standard_error(lm_results[\"Y_target\"], lm_results[\"Y_predicted\"], X_test, feature_variables)\n",
    "    print(\"The Standard Error (SE) is:\", SE)\n",
    "   \n",
    "    return lm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first try to predict our target variable using features with correlation threshold > 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model works really well but let's try to increase the accuracy further by including more features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This shows that even though we used more features, the model accuracy changed by a really small percentage as the features we added have a weak correlation with the target variable. However, we will use this model as it provides higher accuracy.# (not yet sure of this comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAIjCAYAAAAtE/I+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABX2klEQVR4nO3deXxU1f3/8fc4gZAiCbInJBBEEEGLC+q3ajAIFS0iGpFFpSx1q1iJFFx+PlBckOIKVZTSUrVlUQuDRW1rkW8C4euCiFD9VlFoQAi4a0JQWSb398f9TmSSSTJ3MnfuvTOv5+MxjzB3DjefOZOZfHLuOZ/jMwzDEAAAAOABRzkdAAAAABAtklcAAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZJK8AAADwDJJXAIiRz+fTzJkznQ7DcYWFhSosLKy9v2PHDvl8Pj399NOOxVRX3RgBeBfJKwBXeOKJJ+Tz+XTmmWfGfI49e/Zo5syZ2rx5c/wCc7nS0lL5fL7aW4sWLXTsscfq5z//uf7zn/84HZ4lr732mmbOnKlvvvnG6VAAuFia0wEAgCQtWbJE+fn52rBhg7Zt26bjjjvO8jn27Nmju+++W/n5+Tr55JPjH6SL3XTTTTr99NN16NAhbdq0SQsXLtTLL7+sd999Vzk5OQmNpXv37vruu+/UokULS//vtdde0913360JEyaobdu29gQHwPMYeQXguPLycr322mt65JFH1LFjRy1ZssTpkDynoKBAV111lSZOnKjHHntMDz30kL766is988wzDf6f/fv32xKLz+dTq1at5Pf7bTk/gNRG8grAcUuWLNExxxyjYcOGaeTIkQ0mr998841uvvlm5efnKz09Xbm5ufr5z3+uL774QqWlpTr99NMlSRMnTqy9jB6ad5mfn68JEybUO2fduZAHDx7UnXfeqdNOO01ZWVlq3bq1CgoKVFJSYvl5ffrpp0pLS9Pdd99d77GtW7fK5/Pp8ccflyQdOnRId999t3r16qVWrVqpffv2Ouecc7R69WrL31eSzjvvPEnmHwaSNHPmTPl8Pv373//WFVdcoWOOOUbnnHNObfvFixfrtNNOU0ZGhtq1a6cxY8Zo165d9c67cOFC9ezZUxkZGTrjjDNUVlZWr01Dc14/+OADjRo1Sh07dlRGRoaOP/543XHHHbXxTZ8+XZLUo0eP2tdvx44dtsQIwLuYNgDAcUuWLFFRUZFatmypsWPH6sknn9Rbb71Vm4xKUnV1tQoKCvT+++9r0qRJOvXUU/XFF19o1apV2r17t0444QTdc889uvPOO3XttdeqoKBAknTWWWdZiqWqqkp/+MMfNHbsWF1zzTXat2+fFi1apKFDh2rDhg2WpiN07txZ5557rp5//nndddddYY8999xz8vv9uvzyyyWZydvs2bN19dVX64wzzlBVVZU2btyoTZs26ac//aml5yBJ27dvlyS1b98+7Pjll1+uXr166f7775dhGJKkWbNmacaMGRo1apSuvvpqff7553rsscc0cOBAvfPOO7WX8BctWqTrrrtOZ511loqLi/Wf//xHF198sdq1a6e8vLxG4/nXv/6lgoICtWjRQtdee63y8/O1fft2vfjii5o1a5aKior04YcfatmyZXr00UfVoUMHSVLHjh0TFiMAjzAAwEEbN240JBmrV682DMMwampqjNzcXGPKlClh7e68805DkhEIBOqdo6amxjAMw3jrrbcMScZTTz1Vr0337t2N8ePH1zt+7rnnGueee27t/cOHDxsHDhwIa/P1118bnTt3NiZNmhR2XJJx1113Nfr8fve73xmSjHfffTfseN++fY3zzjuv9n7//v2NYcOGNXquSEpKSgxJxh//+Efj888/N/bs2WO8/PLLRn5+vuHz+Yy33nrLMAzDuOuuuwxJxtixY8P+/44dOwy/32/MmjUr7Pi7775rpKWl1R4/ePCg0alTJ+Pkk08O65+FCxcaksL6sLy8vN7rMHDgQKNNmzbGzp07w75P6LUzDMN48MEHDUlGeXm57TEC8C6mDQBw1JIlS9S5c2cNGjRIkjlfcvTo0Xr22WcVDAZr261YsUL9+/fXpZdeWu8cPp8vbvH4/X61bNlSklRTU6OvvvpKhw8f1oABA7Rp0ybL5ysqKlJaWpqee+652mPvvfee/v3vf2v06NG1x9q2bav//d//1UcffRRT3JMmTVLHjh2Vk5OjYcOGaf/+/XrmmWc0YMCAsHbXX3992P1AIKCamhqNGjVKX3zxRe2tS5cu6tWrV+10iY0bN+qzzz7T9ddfX9s/kjRhwgRlZWU1Gtvnn3+udevWadKkSerWrVvYY9G8domIEYB3MG0AgGOCwaCeffZZDRo0qHZupiSdeeaZevjhh7VmzRqdf/75kszL4JdddllC4nrmmWf08MMP64MPPtChQ4dqj/fo0cPyuTp06KDBgwfr+eef17333ivJnDKQlpamoqKi2nb33HOPRowYod69e+vEE0/UBRdcoHHjxunHP/5xVN/nzjvvVEFBgfx+vzp06KATTjhBaWn1P+LrPoePPvpIhmGoV69eEc8bqhiwc+dOSarXLlSaqzGhkl0nnnhiVM+lrkTECMA7SF4BOOa///u/tXfvXj377LN69tln6z2+ZMmS2uS1uRoa4QsGg2Gr4hcvXqwJEybokksu0fTp09WpUyf5/X7Nnj27dh6pVWPGjNHEiRO1efNmnXzyyXr++ec1ePDg2nmdkjRw4EBt375df/3rX/XPf/5Tf/jDH/Too49qwYIFuvrqq5v8HieddJKGDBnSZLuMjIyw+zU1NfL5fPr73/8esTrA0UcfHcUztJcXYgSQOCSvAByzZMkSderUSfPnz6/3WCAQ0MqVK7VgwQJlZGSoZ8+eeu+99xo9X2OXoI855piIxe937twZNiq3fPlyHXvssQoEAmHnq7vgyopLLrlE1113Xe3UgQ8//FC33357vXbt2rXTxIkTNXHiRFVXV2vgwIGaOXNmVMlrrHr27CnDMNSjRw/17t27wXbdu3eXZI6ChioZSGaVhPLycvXv37/B/xvq31hfv0TECMA7mPMKwBHfffedAoGALrroIo0cObLe7cYbb9S+ffu0atUqSdJll12mLVu2aOXKlfXOZfzfqvnWrVtLUsQktWfPnnrjjTd08ODB2mMvvfRSvVJLoZG90Dkl6c0339Trr78e83Nt27athg4dqueff17PPvusWrZsqUsuuSSszZdffhl2/+ijj9Zxxx2nAwcOxPx9o1FUVCS/36+777477DlLZh+E4howYIA6duyoBQsWhPXh008/3eSOWB07dtTAgQP1xz/+UR9//HG97xHS0OuXiBgBeAcjrwAcsWrVKu3bt08XX3xxxMf/67/+q3bDgtGjR2v69Olavny5Lr/8ck2aNEmnnXaavvrqK61atUoLFixQ//791bNnT7Vt21YLFixQmzZt1Lp1a5155pnq0aOHrr76ai1fvlwXXHCBRo0ape3bt2vx4sXq2bNn2Pe96KKLFAgEdOmll2rYsGEqLy/XggUL1LdvX1VXV8f8fEePHq2rrrpKTzzxhIYOHVpvB6m+ffuqsLBQp512mtq1a6eNGzdq+fLluvHGG2P+ntHo2bOn7rvvPt1+++3asWOHLrnkErVp00bl5eVauXKlrr32Wk2bNk0tWrTQfffdp+uuu07nnXeeRo8erfLycj311FNRzSf97W9/q3POOUennnqqrr32WvXo0UM7duzQyy+/XLud72mnnSZJuuOOOzRmzBi1aNFCw4cPT1iMADzCoSoHAFLc8OHDjVatWhn79+9vsM2ECROMFi1aGF988YVhGIbx5ZdfGjfeeKPRtWtXo2XLlkZubq4xfvz42scNwzD++te/Gn379jXS0tLqlWt6+OGHja5duxrp6enG2WefbWzcuLFeqayamhrj/vvvN7p3726kp6cbp5xyivHSSy8Z48ePN7p37x4Wn6IolRVSVVVlZGRkGJKMxYsX13v8vvvuM8444wyjbdu2RkZGhtGnTx9j1qxZxsGDBxs9b6hU1l/+8pdG24VKZX3++ecRH1+xYoVxzjnnGK1btzZat25t9OnTx5g8ebKxdevWsHZPPPGE0aNHDyM9Pd0YMGCAsW7dunp9GKlUlmEYxnvvvWdceumlRtu2bY1WrVoZxx9/vDFjxoywNvfee6/RtWtX46ijjqpXNiueMQLwLp9h1LkGAwAAALgUc14BAADgGSSvAAAA8AySVwAAAHgGySsAAAA8g+QVAAAAnkHyCgAAAM9I+k0KampqtGfPHrVp06bRrSMBAADgDMMwtG/fPuXk5OiooxofW0365HXPnj3Ky8tzOgwAAAA0YdeuXcrNzW20TdInr23atJFkdkZmZqbD0QAAAKCuqqoq5eXl1eZtjUn65DU0VSAzM5PkFQAAwMWimeLJgi0AAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZJK8AAADwDJJXAAAAeAbJKwAAADyD5BUAAACeQfIKAAAAzyB5BQAAgGekOR0AAACRBINSWZm0d6+UnS0VFEh+v9NRAXAaySsAwHUCAWnKFGn37h+O5eZK8+ZJRUXOxQXAeUwbAAC4SiAgjRwZnrhKUkWFeTwQcCYuAO5A8goAcI1g0BxxNYz6j4WOFReb7QCkJpJXAIBrlJXVH3E9kmFIu3aZ7QCkJpJXAIBr7N0b33YAkg/JKwDANbKz49sOQPIheQUAuEZBgVlVwOeL/LjPJ+Xlme0ApCaSVwCAa/j9ZjksqX4CG7o/dy71XoFURvIKAHCVoiJp+XKpa9fw47m55nHqvAKpjU0KAACuU1QkjRjBDlsA6iN5BQC4kt8vFRY6HQUAt2HaAAAAADyD5BUAAACeQfIKAAAAzyB5BQAAgGewYAsAAMBhwSDVNaJF8goAAOCgQECaMkXavfuHY7m55oYd1DWuj2kDAAAADgkEpJEjwxNXSaqoMI8HAs7E5WYkrwAAAA4IBs0RV8Oo/1joWHGx2Q4/IHkFAABwQFlZ/RHXIxmGtGuX2Q4/IHkFAABwwN698W2XKhxNXtetW6fhw4crJydHPp9PL7zwQoNtr7/+evl8Ps2dOzdh8QEAANglOzu+7VKFo8nr/v371b9/f82fP7/RditXrtQbb7yhnJycBEUGAABgr4ICs6qAzxf5cZ9Pyssz2+EHjpbKuvDCC3XhhRc22qaiokK/+tWv9Morr2jYsGEJigwAAMBefr9ZDmvkSDNRPXLhViihnTuXeq91uXrOa01NjcaNG6fp06erX79+Uf2fAwcOqKqqKuwGAADgRkVF0vLlUteu4cdzc83j1Hmtz9WbFMyZM0dpaWm66aabov4/s2fP1t13321jVAAAAPFTVCSNGMEOW9FybfL69ttva968edq0aZN8DU0GieD222/X1KlTa+9XVVUpLy/PjhABAADiwu+XCgudjsIbXDttoKysTJ999pm6deumtLQ0paWlaefOnfr1r3+t/Pz8Bv9fenq6MjMzw24AAABIDq4deR03bpyGDBkSdmzo0KEaN26cJk6c6FBUAAAAcJKjyWt1dbW2bdtWe7+8vFybN29Wu3bt1K1bN7Vv3z6sfYsWLdSlSxcdf/zxiQ4VAAAALuBo8rpx40YNGjSo9n5orur48eP19NNPOxQVAAAA3MrR5LWwsFDGkUXNmrBjxw77ggEAAIDruXbBFgAAAFAXySsAAAA8g+QVAAAAnkHyCgAAAM8geQUAAIBnkLwCAADAM0heAQAA4Bmu3R4WAADAimBQKiuT9u6VsrOlggLJ73c6Ku9xez+SvAIAAM8LBKQpU6Tdu384lpsrzZsnFRU5F5fXeKEfmTYAAAA8LRCQRo4MT7gkqaLCPB4IOBOX13ilH32Glf1ZPaiqqkpZWVmqrKxUZmam0+EAAIA4Cgal/Pz6CVeIz2eOHJaXu+vSt9s43Y9W8jVGXgEAgGeVlTWccEmSYUi7dpnt0DAv9SNzXgEAcJDbF8e43d698W3XkGR/nRLVj/FA8goAgEO8sDjG7bKz49suklR4nRLRj/HCnFcAABwQWhxT97ewz2d+Xb48eRIjO4XmalZU1O9LqflzNVPldbK7H5vCnFcAAFwsGDRH8iIlCaFjxcVmOzTO7zdHQKUfEsqQ0P25c2NLuFLpdbKzH+ON5BUAgATz0uIYLygqMkdAu3YNP56b27yR0VR7nezqx3hjzisAAAnmpcUxXlFUJI0YEd9FVan4OtnRj/FG8goAQIJ5aXGMl/j9UmFh/M6Xqq9TvPsx3pg2AABAghUUmJdi684tDPH5pLw8s11dwaBUWiotW2Z+TYb5lm7VnNcJ9iF5BQAgwWJdHBMImCvCBw2SrrjC/Jqf755tO5ONlxYxpRKSVwAAHGB1cYxX9p1PNl5ZxJRKqPMKAICDotm5yel955H8O2w5zUq+xoItAAAcFM3iGCslm9y80MbL3L6IKZUwbQAAAJdLxZJNQEMYeQUAwOXcWrKJS+lwAiOvAAC4nBtLNlH5AE4heQUAwOXcVrKJygdwEskrACDleLHQv1tKNgWD0pQp5iKxukLHiou90afwJua8AgBSSiBgJl9Hjhrm5pojm26v2emGfeepfACnkbwCAGpZWYDjpsU60cYSutxdd9QwdLnbC0XnrZZsivfrROUDOI3kFQAgydqIZCyjl3Ylu9HG0tTlbp/PvNw9YkRik3A7/wiwY5TZrZUPkEKMJFdZWWlIMiorK50OBQBca8UKw/D5DMNM4364+XzmbcWK2Noe+X9yc8Pb5+ZGbmtX3CUl9dtFupWUNC8mq/Hb0S+hczf2PGP9HocPmzFG6vdQ3+flme2AaFnJ11iwBQApzsoCnFgW69i1Mt1qLG673B1rv0Sz2CwYlK69tvHvf+21sS2qclvlA6QeklcASHFWFuBYaSvZuzLdaixuutwda79EW1u1tFT68svGY/jyS7NdLNxS+QCpieQVAFKclRFJq6OXVhNMK6zG4qZC/7H0i5WR2miT0liTV8lMUHfskEpKpKVLza/l5SSusB8LtgAgxdkxIhlq25xL9U0tZLIad+hy98iRZqJ65KhnU5e7nV6xn8jFZlaeq9XKB3bGgtTByCsApDgrI5JWRy9jTYyjuTwey0hqLJe77dgG1Wq/WB2pjTahrNvOTVu+uikWuEwCFpA5imoDANC00Kr9uivIG6s2EE3bWFamx1L5IJpYjnT4sFlVYOlS82tDK+NjqawQjcOHDaN9+8arAbRv/0NcS5dGVylh6dLYzm/nc42Fm2JBYljJ10heAQCGYUQu25SXF33pq8baWk12G0q4Gkp2o43FilhiOfL/NpYcW00uYynzZaVUVnOea7y5KRYkDsnrEUheASB60Y5IWm0bbYIZay1WK7FEK9ZYoqndavXcsdZWXbHCMLp2bTyW5jxXO7gpFiSOlXyNBVsAgFpWFuBYaVtUZC4mamrxTawLvOxYOBRLLNFuP2v13LEuNrO73+3gpljgTiSvAICEiCbBdFMtVquxWKkIEMvzDC02i7Td69y5DZeoSvZ+R+rxGUakt1nyqKqqUlZWliorK5WZmel0OACARgSD5oryiorISaDPZyZr5eX2l0yyGktpqbkiviklJeboZ6zP047yUV7udyQHK/kapbIAAK7hpq1HrcZi5XJ3c55naCR17Fjzazz6wsv9jtRD8goAcBU3bT1qJRarl7vd9DzdFo+bYoH7MG0AgOexC09yctPrGk0ssV7udtPzdFs8booF9rKSr5G8AvC0QCDyApZ58xidQeKFqg1IkSsCMGoIROaZOa/r1q3T8OHDlZOTI5/PpxdeeCHs8ZkzZ6pPnz5q3bq1jjnmGA0ZMkRvvvmmM8ECcJ1QolB328xQWSK2kUSicbkbsJ+jyev+/fvVv39/zZ8/P+LjvXv31uOPP653331X69evV35+vs4//3x9/vnnCY4UgNs0VZZIMssSBYMJDQseEQya1QGWLTO/xvPnpKhI2rHDrCqwdKn5tbycxDUR7Hxd4R6umTbg8/m0cuVKXXLJJQ22CQ0pv/rqqxo8eHBU52XaAJCcrJQlinfxengbU02SE6+rt1nJ1zyzScHBgwe1cOFCZWVlqX///g22O3DggA4cOFB7v6qqKhHhAUgwduGxR7IvkGloB6zdu8N3wIK3RLuzWXN4+b3h5dgjcX2prJdeeklHH320WrVqpUcffVSrV69Whw4dGmw/e/ZsZWVl1d7y8vISGC2ARGEXnvgLBMzV8oMGSVdcYX7Nz0+eucONTTWRzONMNfGeREwh8vJ7w8uxN8T1yeugQYO0efNmvfbaa7rgggs0atQoffbZZw22v/3221VZWVl727VrVwKjBZAoBQXmJcG6RcxDfD4pL89sh6alwuK3srL6z6+uXbvMdvCOpl5Xw2je6+rl94aXY2+M65PX1q1b67jjjtN//dd/adGiRUpLS9OiRYsabJ+enq7MzMywG4Dkwy488ZMqi98qKuLbDu5YIGXnFCIvvze8HHtTXJ+81lVTUxM2pxVA6qIsUXzYPXIV4nSiE22hmkjtnI7djdxyOdrOKUSJem/YwcuxN8XRBVvV1dXatm1b7f3y8nJt3rxZ7dq1U/v27TVr1ixdfPHFys7O1hdffKH58+eroqJCl19+uYNRA3CToiJpxIjkWoyQaIlY/OaGleAdO8bWzg2xu00iFkhFKzSFqKmdzWKZQuTlhaFejr0pjiavGzdu1KAjat1MnTpVkjR+/HgtWLBAH3zwgZ555hl98cUXat++vU4//XSVlZWpX79+ToUMwIX8fsphNYfdi9/ckujUHaGPpl0yrGKP9/mbuhzt85mXo0eMSMwfkaEpRCNHmt870s5msU4h8vLCUC/H3hTX1Hm1C3VeAaBxwaB5ubexS4x5eWahfasJQFPnDo2KxXJuq6w+z0TEbveorh3nd2uN5UjPNS/PTFxjfa6hn4GmRnUT8fNrlddi98z2sAAA5/n90tixjbcZMya2X3Bumk8bGqHz+SIv8vP5wkfovL6K3a7zu/VytB07m3l5YaiXY28KySsApLhg0Ez6GvPss7EtUkrUfNpoFw41tMiva9f6UwDcuoo9mkTdzpXmbr4cHZpCNHas+TUeiZmXF4Z6OfbGkLwCQIqzs/5pIubTXnZZ/fh37zaPNzS6WDepi5TkuXEVe7SJup2jxqlYY9mOUd1E8XLsDfHM9rAAAHvYOcJo50rwYFC69trG21x7bfjCoYYWYO3ZU38BVkGB1L699OWXDZ+/ffvErWK3snisOa9pUwu87Fwg5WZeXhjq5dgjYeQVAFKcnSOMds67Ky1tPLGUzMdLS81/u6lou9U+txp7rK9ptCO7yXo5Gt5A8goAKc7uy8B2JTqhpDTadlYvpZeVRZccJ+LSu9XYY3lNrS7wSsbL0fAGklcASHGJWJXshkTH6qV0O6dTWO1zq7FYPX+so9J2LJA6EjubIRKSVwBAQi4DxzvRiXYOX6id1Uvpdi82s9LnscRi5fxu3ErULdvPwn3YpAAAUMvu3Z7iKRiUOnduekHVp5+GbzoQbdH2RBV5j6bPmxNLNOdftsxMEJuydGnTNYHjoaHFaaFRY+bVJh8r+RrVBgAAtby0KtnvlxYuNEtiNWThwh8SNaur5BO1qj6aPm9OLNGc3021W922/Szch2kDAADPKiqSVqyIfGl8xYr6o3NWp0e4aVW9nbG4qXarG6cwwF2YNgAA8Dyr0x3sbm8nu2IJXaqXIo/sJipZd9sUBiQG0wYAACnF6nQHu9vbya5YQiO7U6aEj3zm5ppTEhI1yuymKQxwJ0ZeAQBALadHmRO1UA7uwsgrAABxZGdCd/Cg9MQT0vbtUs+e0g03SC1bxufcsXB6lDlVt59F9FiwBQBAI+ysN3rLLdKPfiTdfLP0+OPm1x/9yDyeyty0UA7uw7QBAEDKiXYk1c56o7fcIj34YMOPT58uPfBAbOduDqenDbg1FtjLSr5G8goASCmBQORFSfPmhSeiobmXDZVtas7cy4MHzRHWxrY79fulb7+tP4XAzoQu2r4B4s1Kvsa0AQBAygiNpNZNSCsqzONHTgWws97oE080nrhK5uNPPBF+zM4pDFb6BnASySsAICU0tXOTZO7cFEoq9+6N7ryR2gWDUmmpWbO0tLR+orp9e3TnPrKdncml1b4BnETyCgBICVZHUmOtNxrN6GjPntGdO9TO7uSSXa3gJSSvAICUYHUkNZYtU6MdHb3hBumoJn4DH3WU2U6yP7lszigzkGgkrwCAlGB1JDVUb1Sqn8BGqjdqZXTU7zcXbDXmRz/64dx2J5fsagUvIXkFAKSEWEZSrdQbtTI6WlYmVVc3Hm91dfOnMEQrlr4BnELyCgBICVZHUkOKisyFU48+Kt14o/l127b6paOsjI4mYgqDFbH2DeAEktc4amp1KQDAWaGR1Jyc8ONduza84UAgYC6cOnIXrJ4966/utzI6GusUhoYqsxtG85NLdrVCiNvzmTSnA0gWFHYGAO9oaASzroZ22AotwDoyqQuNjlZURE4yQ5sahEZHrbRNlKIiacQIdrVKZV7IZ9hhKw7s3D4QABA/Vj6vY9lhK3R+Kfx7RDq/lbZ27vYFhDiZz7DDVgJR2BkAvMHq53Us5amsXHq3azEYEAsv5TNMG2gmKx8ohYUJCwsAUIfVz+tYy1NZufQebVvqsMJuXspnSF6biQ8UAPAGq5/XzSlP5ffH9xc8dVhhNy/lM0wbaCY+UADAG6x+Xiei9mk0W8kmKhakNi/lMySvzcQHCgB4g9XPa7trn0a7lWwiYgG8lM+QvDYTHygA4A2xfF7bVfs0lsUx1GGFnbyUz1AqK04i1UXLyzNfaD5QAMA9Yvm8DgbjW/u0tNScItCUkpL6c2fjHQtwJKfyGSv5GslrHPGBAgDe4PTn9bJl5hzXpixdKo0da388wJGceH9YydeoNhBH8V5dCgCwh9Of115aHIPU4/T7oykkrwASwumRrmRx8KD0xBPS9u1Sz57SDTdILVs6HRWssrqVLIAfkLwCsJ0X9sp2ipWk/pZbpEceCV/EM22aNHWq9MADiYk3VcX7j6/Q4pjLLov8uGE4tziGPzThdlQbAGArK+WAUk20NT4lM3F98MH6WzMGg+bxW25JRMSpycrr5HWp9FzhXSzYAmCbYND8xdfQloOhS6Pl5ak3shNK6ut+AodK0hxZ+ujgQelHP2p8T3G/X/r22+ZPIfDqtAS7RgutvE5W43Xbe8Ou5wpEw0q+xsgrANtY2Ss7lVit8fnEE40nrqFzPvFE8+K65RYzSb75Zunxx82vP/qR+0d17RotjKUWa7Tc9t6w87kC8UbyCsA2XtorO5GsJi7bt0d33mjbReLVaQl2TkuxM8F023vDbck00BiSVwC2oRxQZFYTl549o2sfbbu6Dh40F4I15pFHzHZuYvdooZ0JZnPeG8GgucnBsmXm13iMhrotmQYaQ/IKwDZe2is7kawmLjfc0PS8R7/fbBeLRE1LiDe7Rwvt/OMr1veGXVMk+EMTXkLyCsA2XtorO5GsJi4tW5rlsBozdWrsC6sSMS3BDnaPFtr5x1cs7w07p0jwhya8hOQVgK2KisxVyl27hh/PzU3d1cuxJC4PPCBNn14/0ff7zePNqfNq97QEu9h96b05f3xFc34r7w27p0jwhya8hFJZABKCwuf1Rdq8IS/PTBIaSurtKGWVyFJc8RQqN9XULlV1y01Z3TTD6utk9fzRvDdKS80pAk0pKWnetp6x/EwC8WAlXyN5BQAHuSWpD1UbaEhzR3djEU3fhC6lS+EJbEO1SWOtZRrt62RXrdRly8w5rk1ZulQaO9b6+Y/klp9JpBZL+ZrhoLVr1xoXXXSRkZ2dbUgyVq5cWfvYwYMHjVtuucU48cQTjR/96EdGdna2MW7cOKOiosLS96isrDQkGZWVlXGOHgCSy/TphuH3G4aZepk3v988nmgrVhhGbm54LLm55vFo2ubl1W97+HD9dkfefD7z/x0+HFvMdp6/pKTh8x55KymJLXbAaVbyNUfnvO7fv1/9+/fX/Pnz6z327bffatOmTZoxY4Y2bdqkQCCgrVu36uKLL3YgUgBIfg88YE4NePRR6cYbza/ffpv4EVerC5OKiqQdO8xL5kuXml/Ly+uPcNpdncDO87OgCvhBmpPf/MILL9SFF14Y8bGsrCytXr067Njjjz+uM844Qx9//LG6deuWiBABIKW0bGku/HFKUwuTfD4zvhEjwi9l+/1Nz/W0uzqBnecPLagKTZGIhAVVSBWeqjZQWVkpn8+ntm3bNtjmwIEDqqqqCrsBALzBztFLu2uZ2n3+oiJp2rTIFSemTYvfgio7NkFwo1R5nsnIM8nr999/r1tvvVVjx45tdCLv7NmzlZWVVXvLy8tLYJQAgOawc/TS7kvvdp8/EJAeeqh+klVTYx5v7kYFoe9hxyYIbpMqzzNZeSJ5PXTokEaNGiXDMPTkk0822vb2229XZWVl7W3Xrl0JihIA0Fx2jl7aXcvUzvPbXedVsncTBDdJled5pGQbZXZ98hpKXHfu3KnVq1c3WT4hPT1dmZmZYTcAgPOi+QVq9+il3Ztm2HV+uxebJSI5ToSmfsaS5XlakYyjzK5OXkOJ60cffaRXX31V7du3dzokAEAMov0FmoidnqKtTuCm89u92Mzu5DgRovkZS4bnaUWyjjI7Wm2gurpa27Ztq71fXl6uzZs3q127dsrOztbIkSO1adMmvfTSSwoGg/rkk08kSe3atVNLN23zAgBoUEOF+0O/QOuOSIZGLyPtUhWvnZ6iqU5wJKuF+62evyl2LwazOzm2W7Q/Y15/nlbEWrnDCxzdYau0tFSDIux3N378eM2cOVM9evSI+P9KSkpUGOWnAjtsAYBzQlu4NjTa1dAWrqH/64adnqxu92qHWLfCjVaitp+1g5WfsbIy7z5Pq7z2mlrJ1xwdeS0sLFRjubODeTUAIA6sXKat+ws03qOXsbA6amyXI+u8+nyRt8JtznSK0FzjppJjN26CYOVnzMvP06pkHmV29ZxXAIC3efkXqNsW99i52CwRc43tYuVnzMvP0yq7p5o4ieQVAGCb5vwCdbq8jxsX99i52MzuSgx2sfoz5tXnaVUybyns6JzXRGDOKwA4JxiUOneWvvyy4Tbt20uffho+2uWGeabLlpmr1puydKk0dqz98SSKW+YaRyvW+cBee56xCE17kSJPNXFTsu6ZOa8AANTllnmmyXzZtTFumGtsRazzgb32PGORiModTmDkFQBgG6srnptTnSDe7F7hj/iKNFqfl+ftJC1evDDKzMgrAMAVrC7Yak51gnize4U/4quoyKxZ6vYkzQnJNspM8goAsI3VS+9uq06QrJddk1WyJWmIjOQVAGAbq3U13TjPlBE9wF1IXgEAtrF66d2tReQZ0QPcgzqvAABbWamrmUpF5AHEhmoDABLCC6tdYa+DB6UnnpC2b5d69pRuuEFq2TJyW1aOA6nFSr5G8grAdm4oOA9nxfIzwB88QOogeT0CySvgrIYKzrtxhxfYg58BAE0heT0CySvgnEQVnGeEzr3ctOkA4o/3HuLFSr7Ggi0AtrFScD5WgYCZHA0aZO5DP2iQeT8QiP2ciJ9E/AzAGbz34BSSVwC2sbvgfOhydN3kqKLCPM4vUee5bdMBxAfvPTiJ5BWAbewsOB8MmguAIk18Ch0rLjbbwTlu3HQAzcN7D04jeQVgm1DB+br1OkN8PrP8USwF57kc7Q12/gzAGbz34DSSVwC2sbPgfLJcjg4GpdJSadky86vTo1VW4ommLZsOJJ9kee/Bu0heAdjKyu5KViTD5Wi3LXixEo+Vtg39DHTtSpksL0qG9x68jeQVgO2KiqQdO6SSEmnpUvNreXnzkhavX45224IXK/HEGnvdOZLJXagxeXn9vQfvo84rAM8KJVFSeCLk9uL3bqt9aiUeyXrsbtykgPqkzePW9x6vq3dR5xVASrBrSoLd3LbgxUo8VmN348p0t03X8CI3vvd4XVNHmtMBAEBzFBVJI0Z4a7TFbQte7Ign1NZKsltYGP6YHaNoDY0Ch6Y8uPmPHrdx03uP1zW1kLwC8Dy/v37iE0/xTqLctuDFjnhCbWNNjAMBc8T2yMQ3N9esXBApCYnmNWpqFNjnM0eBR4xw9x8/bmL3ey8avK6ph2kDANAIOy5Fhha8NCaRC16sLMCxulgnlsTY6oKwaF8jt03XQHzwuqYeklcAaIBdFQH8fmns2MbbjBkTn1GieNditVq31Wqya3WOrJXXyG3TNRAfvK6ph+QVACKwc6FRMGgmk4159tnmL2KKRy3WSAtwrLS1muxaGUWz+hq5bboG4oPXNfVQKgsAIigtNZO9ppSUWJ/zZ+e5Q2ItT2Vlfq+VtpHmsOblmYnrkXEsW2Ym2k1ZutT8nlb6MVQSrKIicsKb6BJliA9e1+RgJV9jwRYARGDnpUi7L3M2ZwGLlQU4VtpGuzLdyiia1X4MjQKPHGn2QaT6pGxV6z28rqmHaQMAEIGdlyLtvszp1gUsoWR37Fjza6Rkwsoc2Vj60Y31SdF8vK6phWkDABCBnZci7b7MaeXSe1MLx5wQ7e5NzelHdmJKTryu3sUOWwDQTFYXGrnl3JL3F7BEO4rWnH6MZhQY3sPrmhpIXgGgAXZeirTz3FbLU7lRUZG0Y4e52GrpUvNreXn9fuFyMZB6op42UFVVFfVJ3XR5nmkDAJrLzkuRdp072kvvyYLLxYC3WcnXok5ejzrqKPka+jO+jmBzixPGEckrgFQVbXkqAHCaLaWySkpKav+9Y8cO3XbbbZowYYJ+8pOfSJJef/11PfPMM5o9e3aMYQMA4ina8lQA4CUxVRsYPHiwrr76ao2ts0x16dKlWrhwoUpLS+MVX7Mx8goAAOButlcbeP311zVgwIB6xwcMGKANGzbEckoAAACgSTElr3l5efr9739f7/gf/vAH5eXlNTsoAID7BYPmVrfLlplfXbTcAUhqqf7ei2l72EcffVSXXXaZ/v73v+vMM8+UJG3YsEEfffSRVqxYEdcAAQCxs7OaQd3FYLm5Zt1VFoMB9uG914wdtnbt2qUnn3xSH3zwgSTphBNO0PXXX++6kVfmvAJIVXb9kguV4ar72yNZy3ABbpHM7z1bSmV5FckrgERzQ81Ru37JhbZkPTIhrnv+5mxtCySLeH8OJPt7LyHbw5aVlemqq67SWWedpYqKCknSn//8Z61fvz7WUwKA5wUC5i+YQYOkK64wv+bnm8cTJRg0R1wjDU2EjhUXxzZPrqys4V+eofPv2mW2A1KVHZ8DvPd+EFPyumLFCg0dOlQZGRnatGmTDhw4IEmqrKzU/fffH9cAAcArQqOddX/BVFSYxxOVwNr5S27v3vi2A5KNXZ8DvPd+EFPyet9992nBggX6/e9/rxYtWtQeP/vss7Vp06a4BQcAXmHnaKdVdv6Sy86OvV2qr5BuCP0SP073pZ2fA8157yWbmJLXrVu3auDAgfWOZ2Vl6ZtvvmluTADgOW66pGfnL7mCAnNeXUO7hft85ha0BQXhx90wncKN6Jf4cUNf2vk5EOt7LxnFlLx26dJF27Ztq3d8/fr1OvbYY5sdFAB4jZsu6dn5S87vN6sVhM5T97ySNHdu+IIRt0yncBv6JX7c0pd2fg7E8t5LVjElr9dcc42mTJmiN998Uz6fT3v27NGSJUs0bdo0/fKXv4z6POvWrdPw4cOVk5Mjn8+nF154IezxQCCg888/X+3bt5fP59PmzZtjCRcAbOemS3qhX3IN1ZIxjOb9kisqMqsVdO0afjw3t34VAzdNp3AT+iV+3NSXdn8OWHnvJbOYNim47bbbVFNTo8GDB+vbb7/VwIEDlZ6ermnTpulXv/pV1OfZv3+/+vfvr0mTJqkoQo/v379f55xzjkaNGqVrrrkmllABICFCo50VFZF/iYbK2CTLJb2iImnEiKZLAVm5jFpYaGvIrkK/xI+b+jIRnwPRvveSWUzJq8/n0x133KHp06dr27Ztqq6uVt++fXX00UdbOs+FF16oCy+8sMHHx40bJ0nasWNHLGECQMKERjtHjjR/QR35iyvRl/RCI1EN8fnMkagRI5oXj9/fdDLgpukUbkK/xI+b+jJRnwPRvPeSWUzTBiZNmqR9+/apZcuW6tu3r8444wwdffTR2r9/vyZNmhTvGC05cOCAqqqqwm4AkAhuuaSXKovHvIx+iR+39aVbPgeSWUzJ6zPPPKPvvvuu3vHvvvtOf/rTn5odVHPMnj1bWVlZtTe3bVcLILkVFUk7dkglJdLSpebX8vLE/sJy00gUK6Qjo1/ix4196YbPgWRmadpAVVWVDMOQYRjat2+fWrVqVftYMBjU3/72N3Xq1CnuQVpx++23a+rUqbX3q6qqSGABJJTTl/TcNBLlpukUbkK/xI9b+9Lpz4FkZmnktW3btmrXrp18Pp969+6tY445pvbWoUMHTZo0SZMnT7Yr1qikp6crMzMz7AYAqcRtI1FcRo2Mfokf+jK1WBp5LSkpkWEYOu+887RixQq1a9eu9rGWLVuqe/fuysnJiXuQAIDouXEkihXSkdEv8UNfpg5Lyeu5554rSSovL1e3bt3ka+jP+ihVV1eHbXZQXl6uzZs3q127durWrZu++uorffzxx9qzZ48kc2cvydwkoUuXLs363gCQzEIjUVOmhC/eys01E1cnRqK4jBoZ/RI/9GVq8BlGQ2WsG/bUU0/p6KOP1uWXXx52/C9/+Yu+/fZbjR8/PqrzlJaWatCgQfWOjx8/Xk8//bSefvppTZw4sd7jd911l2bOnBnV96iqqlJWVpYqKyuZQgAg5QSDjEQBcD8r+VpMyWvv3r31u9/9rl7iuXbtWl177bW1I6RuQPIKAO5AIg2gIVbytZg2Kfj444/Vo0ePese7d++ujz/+OJZTAgCSWCAQeQrDvHkspgFgTUx1Xjt16qR//etf9Y5v2bJF7du3b3ZQAIDkEQiYi8fqbpxQUWEeDwSciQuAN8WUvI4dO1Y33XSTSkpKFAwGFQwG9d///d+aMmWKxowZE+8YASBpBYNSaam0bJn5NRh0OqL4Cm1VG2mCWuhYcXHyPW8A9olp2sC9996rHTt2aPDgwUpLM09RU1Ojn//857r//vvjGiAAJKtUuJRuZataVokDiEZMyWvLli313HPP6d5779WWLVuUkZGhk046Sd27d493fADgODsWGoUupdcdkQxdSvdCYfVo+sVNW9UCSA4xJa8hvXv3Vu/eveMVCwC4jh2jo01dSvf5zEvpI0a4dzV+tP3ipq1qASSHqEtlTZ06Vffee69at26tqVOnNtr2kUceiUtw8UCpLACxamh0NLQ/S6yjo6WlUoQS1/WUlLjzUrqVfgkGpc6dpS+/bPh87dtLn37q3kQdgP1sKZX1zjvv6NChQ7X/bkhzd90CADewc3TUy5fSk2HUGIC3RZ28lpSURPw3ACQjOxcaeflSutV+KStrfNRVMh9nwRaAaMVUKgsAkp2do6MFBeb80IYuVPl8Ul6e2c5trPaLl0eZAbhT1COvRRYmdgWoOA3A4+wcHfX7zYVNI0eaieqRl+BDCe3cue687G61X7w8ynwktrYF3CPqkdesrKzaW2ZmptasWaONGzfWPv72229rzZo1ysrKsiVQAEgku0dHi4rMhU1du4Yfz811d5ksq/3i5VHmkEBAys83F9ldcYX5NT+fncEAp0RdbeBIt956q7766istWLBA/v/70zMYDOqGG25QZmamHnzwwbgHGiuqDQCIVWhVvRR5dDQeSaYXR/Ss9ksi+tEudlWcABDOSr4WU/LasWNHrV+/Xscff3zY8a1bt+qss87Sl03Nzk8gklcAzRGpnmlennlZP5WTFqv94sV+DAbNEdaGFqj5fOaocnm5+//gANzOllJZRzp8+LA++OCDesnrBx98oJqamlhOCQCuVFRkln3y2uio3az2ixf7ka1tAXeKKXmdOHGifvGLX2j79u0644wzJElvvvmmfvOb32jixIlxDRAAnOb3k5xEYrVfvNaPVEoA3Cmm5PWhhx5Sly5d9PDDD2vv/71rs7OzNX36dP3617+Oa4AAADghWSolAMkmpjmvR6qqqpIk184nZc4rACAWoTmvFRWRdxRjzisQP1bytZg3KTh8+LBeffVVLVu2rHZL2D179qi6ujrWUwIA4BqherxS/VJfbq/HCySzmJLXnTt36qSTTtKIESM0efJkff7555KkOXPmaNq0aXENEAAAp3i1Hi+QzGKa8zplyhQNGDBAW7ZsUfv27WuPX3rppbrmmmviFhwAILG8WHfWbl6slAAks5iS17KyMr322mtq2bJl2PH8/HxVVFTEJTAAQGJFqsWam2teOk/1EUavVUoAkllM0wZqamoUDAbrHd+9e7fatGnT7KAAAIkV2kmqbl3TigrzOFuhAnCLmJLX888/X3Pnzq297/P5VF1drbvuuks/+9nP4hUbACABgkFzxDXSinrDMG/FxWY7AHBaTMnrQw89pP/5n/9R37599f333+uKK66onTIwZ86ceMcIALBRUztJST/sJAUATotpzmteXp62bNmi5557Tlu2bFF1dbV+8Ytf6Morr1RGRka8YwQA2CjapQosaQDgBpaT10OHDqlPnz566aWXdOWVV+rKK6+0Iy4AQIL8X7XDuLUDADtZnjbQokULff/993bEAgBwQMeO8W0HAHaKac7r5MmTNWfOHB0+fDje8QAAEqxuAf7mtgMAO8U05/Wtt97SmjVr9M9//lMnnXSSWrduHfZ4gJoqAOAK0Ww6UFBg1nNtbNFWXp7ZDgCcFlPy2rZtW1122WXxjgUAEEfRbjrg95vHRo6MXC7L55PmzmVHKQDuYCl5ramp0YMPPqgPP/xQBw8e1HnnnaeZM2dSYQBIQWwj6m6hTQfqJqOhTQeWLw9PYIuKzGN1k928PDNxTfUdtgC4h88wIv2dHdm9996rmTNnasiQIcrIyNArr7yisWPH6o9//KOdMTZLVVWVsrKyVFlZqczMTKfDAZJCIrYRJTmOXTAo5ec3PA3A5zNfr/Ly+n1KvwNwgpV8zVLy2qtXL02bNk3XXXedJOnVV1/VsGHD9N133+moo2Ja+2U7klcgvhoa0fP5zK91R/Ri/R52J8fJrLRUGjSo6XYlJVJhod3RAEDTrORrljLOjz/+OGz71yFDhsjn82nPnj2xRQrAU5raRlRq/jaioeS47qhh6HI360GbtndvfNsBgJtYSl4PHz6sVq1ahR1r0aKFDh06FNegALhTU9uIGkbzthFNRHKcCrKz49sOANzE0oItwzA0YcIEpaen1x77/vvvdf3114eVy6JUFpCc7B7Rs5Icc7m7YaHSVxUVDVcPyM2l9BUAb7KUvI4fP77esauuuipuwQBwN7tH9LjcHR9Hlr7y+cIT2NDcZEpfAfAqS8nrU089ZVccADzA7hE9LnfHT0Olr3JzKX0FwNssVRvwIqoNAPEVWlAlRR7Ra061gVCJp6aS40glnhAZpa8AeIFt1QYAIDSiV3ef+9zc5pfJCl3uln5IhkO43B0bv9+cHzx2rPmVvgPgdYy8AoiJnSN6keq8emmnJzeNdropFgBoiG2bFHgRySvgTV5Nuty0wYKbYgGAxpC8HoHkFUCiJGL3MS/GAgBNIXk9AskrgEQILTZrqE5tIhebuSkWAIgGC7YAIMHs3n3Mq7EAQLyRvAJAHLhpgwU3xQIA8UbyCgBx4KYNFtwUCwDEG8krAMRBaPexuvVpQ3w+s9xXrLuPeTUWAIg3R5PXdevWafjw4crJyZHP59MLL7wQ9rhhGLrzzjuVnZ2tjIwMDRkyRB999JEzwQIIEwxKpaXSsmXm12DQ6Yic5aYNFtwUCwDEm6PJ6/79+9W/f3/Nnz8/4uMPPPCAfvvb32rBggV688031bp1aw0dOlTff/99giMFcKRAwFzNPmiQdMUV5tf8fPN4KrNz9zEvxwIA8eSaUlk+n08rV67UJZdcIskcdc3JydGvf/1rTZs2TZJUWVmpzp076+mnn9aYMWOiOi+lsoD4on5o09y0wYKbYgGAhljJ19ISFJNl5eXl+uSTTzRkyJDaY1lZWTrzzDP1+uuvN5i8HjhwQAcOHKi9X1VVZXusQKoIBs0dmyL9yWsYZgJbXCyNGJHaCZLfLxUWOh2FyU2xAEA8uHbB1ieffCJJ6ty5c9jxzp071z4WyezZs5WVlVV7y8vLszVOIJVQPxQA4DTXJq+xuv3221VZWVl727Vrl9MhAUmD+qEAAKe5Nnnt0qWLJOnTTz8NO/7pp5/WPhZJenq6MjMzw24A4oP6oQAAp7k2ee3Ro4e6dOmiNWvW1B6rqqrSm2++qZ/85CcORgakLuqHAgCc5uiCrerqam3btq32fnl5uTZv3qx27dqpW7duKi4u1n333adevXqpR48emjFjhnJycmorEgBIrFD90JEjzUT1yIVb1A8FACSCo8nrxo0bNWjQoNr7U6dOlSSNHz9eTz/9tG655Rbt379f1157rb755hudc845+sc//qFWrVo5FTKQ8kL1Q6dMCV+8lZtrJq6pXiYLAGAv19R5tQt1XgF7UD8UABAvSVHnFYC7UT8UAOAE1y7YAgAAAOoieQUAAIBnkLwCAADAM0heAQAA4BkkrwAAAPAMqg0AAOAhlKlDqiN5BQDAIwKByBuEzJvHBiFIHUwbAADAAwIBc2vmIxNXSaqoMI8HAs7EBSQaySsAAC4XDJojrpH2xAwdKy422wHJjuQVAACXKyurP+J6JMOQdu0y2wHJjuQVAACX27s3vu0ALyN5BQDA5bKz49sO8DKSVwAAXK6gwKwq4PNFftznk/LyzHZAsiN5BQDA5fx+sxyWVD+BDd2fO5d6r0gNJK8AAHhAUZG0fLnUtWv48dxc8zh1XpEq2KQAAACPKCqSRoxghy2kNpJXAAA8xO+XCgudjgJwDtMGAAAA4BkkrwAAAPAMklcAAAB4BnNeAbhSMMiiFABAfSSvAFwnEJCmTAnfyz0316xzSTkgAEhtTBsAEJNgUCotlZYtM78Gg/E5byAgjRwZnrhKUkWFeTwQiM/3AQB4E8krAMsCASk/Xxo0SLriCvNrfn7zE8tg0BxxNYz6j4WOFRfHL1EGAHgPySsAS+wcGS0rq3/eIxmGtGuX2Q4AkJpIXgFEze6R0b1749sOAJB8SF4BRM3ukdHs7Pi2AwAkH5JXAFGze2S0oMCsKuDzRX7c55Py8sx2AIDURPIKIGp2j4z6/WY5LKl+Ahu6P3cu9V4BIJWRvAKIWiJGRouKpOXLpa5dw4/n5prHqfMKAKmNTQoARC00MjpypJmoHrlwK54jo0VF0ogR7LAFAKiP5BWAJaGR0Ug7YM2dG7+RUb9fKiyMz7kAAMmD5BWAZYyMAgCcQvIKICaMjAIAnMCCLQAAAHgGySsAAAA8g+QVAAAAnkHyCgAAAM8geQUAAIBnkLwCAADAM0heAQAA4BkkrwAAAPAMklcAAAB4BskrAAAAPIPkFQAAAJ6R5nQAAABvCgalsjJp714pO1sqKJD8fqejApDsSF4BAJYFAtKUKdLu3T8cy82V5s2TioqciwtA8nP9tIF9+/apuLhY3bt3V0ZGhs466yy99dZbTocFACkrEJBGjgxPXCWposI8Hgg4ExeA1OD65PXqq6/W6tWr9ec//1nvvvuuzj//fA0ZMkQVFRVOhwYAKScYNEdcDaP+Y6FjxcVmOwCwg6uT1++++04rVqzQAw88oIEDB+q4447TzJkzddxxx+nJJ590OjwASDllZfVHXI9kGNKuXWY7ALCDq+e8Hj58WMFgUK1atQo7npGRofXr10f8PwcOHNCBAwdq71dVVdkaIwCkkr1749sOAKxy9chrmzZt9JOf/ET33nuv9uzZo2AwqMWLF+v111/X3gY+GWfPnq2srKzaW15eXoKjBoDklZ0d33YAYJXPMCLNXHKP7du3a9KkSVq3bp38fr9OPfVU9e7dW2+//bbef//9eu0jjbzm5eWpsrJSmZmZiQwdAJJOMCjl55uLsyL99vD5zKoD5eWUzQIQvaqqKmVlZUWVr7l65FWSevbsqbVr16q6ulq7du3Shg0bdOjQIR177LER26enpyszMzPsBgCID7/fLIclmYnqkUL3584lcQVgH9cnryGtW7dWdna2vv76a73yyisaMWKE0yEBQEoqKpKWL5e6dg0/nptrHqfOKwA7uX7awCuvvCLDMHT88cdr27Ztmj59ulq1aqWysjK1aNGiyf9vZRgaABA9dtgCEC9W8jVXVxuQpMrKSt1+++3avXu32rVrp8suu0yzZs2KKnEFANjH75cKC52OAkCqcf3Ia3Mx8goAAOBuSbVgCwAAAAgheQUAAIBnkLwCAADAM0heAQAA4BkkrwAAAPAMklcAAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZaU4HAADJJhiUysqkvXul7GypoEDy+52OCgCSA8krAMRRICBNmSLt3v3Dsdxcad48qajIubgAIFkwbQAA4iQQkEaODE9cJamiwjweCDgTFwAkE5JXAIiDYNAccTWM+o+FjhUXm+0AALEjeQWAOCgrqz/ieiTDkHbtMtu5WTAolZZKy5aZX0m2AbgNc14BIA727o1vOycwXxeAFzDyCgBxkJ0d33aJxnxdAF5B8goAcVBQYI5S+nyRH/f5pLw8s53bMF8XgJeQvAJAHPj95uV1qX4CG7o/d647670my3xdAKmB5BUA4qSoSFq+XOraNfx4bq553K3zRpNhvi6A1MGCLQCIo6IiacQIb+2w5fX5ugBSC8krAMSZ3y8VFjodRfRC83UrKiLPe/X5zMfdOF8XQOph2gAApDgvz9cFkHpIXgEAnp2vCyD1MG0AACDJm/N1AaQeklcAQC2vzdcFkHqYNgAAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZJK8AAADwDJJXAAAAeAbJKwAAADyD5BUAAACeQfIKAAAAzyB5BQAAgGewPSwAVwoGpbIyae9eKTtbKigwty4FAKQ2klcArhMISFOmSLt3/3AsN1eaN08qKnIuLgCA85g2AMBVAgFp5MjwxFWSKirM44GAM3EBANyB5BWAawSD5oirYdR/LHSsuNhsB+cFg1JpqbRsmfmV1wVAIpC8AnCNsrL6I65HMgxp1y6zHZwVCEj5+dKgQdIVV5hf8/MZGQdgP5JXAK6xd29828EeTO0A4CSSVwCukZ0d33bJyOlL9UztAOA0klcArlFQYFYV8PkiP+7zSXl5ZrtU5IZL9UztAOA0klcAruH3m+WwpPoJbOj+3LmpWe/VLZfqmdoBwGkkrwBcpahIWr5c6to1/Hhurnk8Feu8uulSPVM7ADjNZxiRPg6TR1VVlbKyslRZWanMzEynwwEQJXbY+kFpqTlFoCklJVJhob2xBIPmVIWKisjJtM9n/qFRXp66rxcA66zka64eeQ0Gg5oxY4Z69OihjIwM9ezZU/fee6+SPN8GIDPxKSyUxo41v6ZyIuSmS/VM7QDgNFcnr3PmzNGTTz6pxx9/XO+//77mzJmjBx54QI899pjToQFAwrjtUj1TOwA4ydXTBi666CJ17txZixYtqj122WWXKSMjQ4sXL47qHEwbAOB1br1Uz9QOAPGSNNMGzjrrLK1Zs0YffvihJGnLli1av369Lrzwwgb/z4EDB1RVVRV2AwC3iqZuq1sv1TO1A4ATXJ283nbbbRozZoz69OmjFi1a6JRTTlFxcbGuvPLKBv/P7NmzlZWVVXvLy8tLYMQAED0rdVu5VA8AJldPG3j22Wc1ffp0Pfjgg+rXr582b96s4uJiPfLIIxo/fnzE/3PgwAEdOHCg9n5VVZXy8vKYNgDAVUJ1W+t+AodGUhtKSLlUDyAZWZk24OrkNS8vT7fddpsmT55ce+y+++7T4sWL9cEHH0R1Dua8AnCb0BzWhnaqotwUgFSTNHNev/32Wx11VHiIfr9fNTU1DkUEAM3HFqsAELs0pwNozPDhwzVr1ix169ZN/fr10zvvvKNHHnlEkyZNcjo0AIiZm+q2AoDXuDp5feyxxzRjxgzdcMMN+uyzz5STk6PrrrtOd955p9OhAUDM3Fa3FQC8xNVzXuOBOa8A3MatdVsBwClJM+cVAJKRW+u2AoAXkLwCgAOo2woAsXH1nFcASGZFRdKIEd6t20rNWQBOIHkFAAeFtlj1mkBAmjIlvORXbq45HYJRYwB2YtoAAMCS0O5gdWvVVlSYxyNtbwsA8ULyCgCIWjBojrhGqpIQOlZcbLYDADuQvAIAosbuYACcRvIKAIgau4MBcBrJKwAgauwOBsBpJK8AgKgVFJhVBepurhDi80l5eWY7ALADySsAIGrsDgbAaSSvAABL2B0MgJPYpAAAYJnXdwcD4F0krwCAmHh1dzAA3sa0AQAAAHgGySsAAAA8g+QVAAAAnkHyCgAAAM8geQUAAIBnkLwCAADAM0heAQAA4BkkrwAAAPAMklcAAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZJK8AAADwjDSnAwAA2CcYlMrKpL17pexsqaBA8vudjgoAYkfyCgBJKhCQpkyRdu/+4VhurjRvnlRU5FxcANAcTBsAgCQUCEgjR4YnrpJUUWEeDwSciQsAmovkFQCSTDBojrgaRv3HQseKi812AOA1JK8AkGTKyuqPuB7JMKRdu8x2AOA1JK8AkGT27o1vOwBwE5JXAEgy2dnxbQcAbkLyCgBJpqDArCrg80V+3OeT8vLMdgDgNSSvAJBk/H6zHJZUP4EN3Z87l3qvALyJ5BUAklBRkbR8udS1a/jx3FzzOHVeAXgVmxQAQJIqKpJGjGCHLQDJheQVAJKY3y8VFjodBQDED9MGAAAA4BkkrwAAAPAMklcAAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPcH3ymp+fL5/PV+82efJkp0MDAABAgrm+zutbb72lYDBYe/+9997TT3/6U11++eUORgUAAAAnuD557dixY9j93/zmN+rZs6fOPfdchyICAACAU1yfvB7p4MGDWrx4saZOnSqfzxexzYEDB3TgwIHa+1VVVYkKDwAAADZz/ZzXI73wwgv65ptvNGHChAbbzJ49W1lZWbW3vLy8xAUIAAAAW/kMwzCcDiJaQ4cOVcuWLfXiiy822CbSyGteXp4qKyuVmZmZiDABAABgQVVVlbKysqLK1zwzbWDnzp169dVXFQgEGm2Xnp6u9PT0BEUFAACARPJM8vrUU0+pU6dOGjZsmKX/FxpYZu4rAACAO4XytGgmBHgiea2pqdFTTz2l8ePHKy3NWsj79u2TJOa+AgAAuNy+ffuUlZXVaBtPzHn95z//qaFDh2rr1q3q3bu3pf9bU1OjPXv2qE2bNg1WKHBSaE7url27mJN7BPqlYfRNZPRLw+ibyOiXhtE3kdEvDWtu3xiGoX379iknJ0dHHdV4PQFPjLyef/75UQ0jR3LUUUcpNzc3zhHFX2ZmJm+ECOiXhtE3kdEvDaNvIqNfGkbfREa/NKw5fdPUiGuIp0plAQAAILWRvAIAAMAzSF4dlp6errvuuovyXnXQLw2jbyKjXxpG30RGvzSMvomMfmlYIvvGEwu2AAAAAImRVwAAAHgIySsAAAA8g+QVAAAAnkHyCgAAAM8geXXI7Nmzdfrpp6tNmzbq1KmTLrnkEm3dutXpsFznN7/5jXw+n4qLi50OxXEVFRW66qqr1L59e2VkZOikk07Sxo0bnQ7LccFgUDNmzFCPHj2UkZGhnj176t577415YxMvW7dunYYPH66cnBz5fD698MILYY8bhqE777xT2dnZysjI0JAhQ/TRRx85E2wCNdYvhw4d0q233qqTTjpJrVu3Vk5Ojn7+859rz549zgWcIE39vBzp+uuvl8/n09y5cxMWn5Oi6Zv3339fF198sbKystS6dWudfvrp+vjjjxMfbAI11S/V1dW68cYblZubq4yMDPXt21cLFiyIexwkrw5Zu3atJk+erDfeeEOrV6/WoUOHdP7552v//v1Oh+Yab731ln73u9/pxz/+sdOhOO7rr7/W2WefrRYtWujvf/+7/v3vf+vhhx/WMccc43RojpszZ46efPJJPf7443r//fc1Z84cPfDAA3rsscecDi3h9u/fr/79+2v+/PkRH3/ggQf029/+VgsWLNCbb76p1q1ba+jQofr+++8THGliNdYv3377rTZt2qQZM2Zo06ZNCgQC2rp1qy6++GIHIk2spn5eQlauXKk33nhDOTk5CYrMeU31zfbt23XOOeeoT58+Ki0t1b/+9S/NmDFDrVq1SnCkidVUv0ydOlX/+Mc/tHjxYr3//vsqLi7WjTfeqFWrVsU3EAOu8NlnnxmSjLVr1zodiivs27fP6NWrl7F69Wrj3HPPNaZMmeJ0SI669dZbjXPOOcfpMFxp2LBhxqRJk8KOFRUVGVdeeaVDEbmDJGPlypW192tqaowuXboYDz74YO2xb775xkhPTzeWLVvmQITOqNsvkWzYsMGQZOzcuTMxQblAQ/2ye/duo2vXrsZ7771ndO/e3Xj00UcTHpvTIvXN6NGjjauuusqZgFwiUr/069fPuOeee8KOnXrqqcYdd9wR1+/NyKtLVFZWSpLatWvncCTuMHnyZA0bNkxDhgxxOhRXWLVqlQYMGKDLL79cnTp10imnnKLf//73ToflCmeddZbWrFmjDz/8UJK0ZcsWrV+/XhdeeKHDkblLeXm5Pvnkk7D3VFZWls4880y9/vrrDkbmPpWVlfL5fGrbtq3ToTiqpqZG48aN0/Tp09WvXz+nw3GNmpoavfzyy+rdu7eGDh2qTp066cwzz2x02kWqOOuss7Rq1SpVVFTIMAyVlJToww8/1Pnnnx/X70Py6gI1NTUqLi7W2WefrRNPPNHpcBz37LPPatOmTZo9e7bTobjGf/7zHz355JPq1auXXnnlFf3yl7/UTTfdpGeeecbp0Bx32223acyYMerTp49atGihU045RcXFxbryyiudDs1VPvnkE0lS586dw4537ty59jFI33//vW699VaNHTtWmZmZTofjqDlz5igtLU033XST06G4ymeffabq6mr95je/0QUXXKB//vOfuvTSS1VUVKS1a9c6HZ6jHnvsMfXt21e5ublq2bKlLrjgAs2fP18DBw6M6/dJi+vZEJPJkyfrvffe0/r1650OxXG7du3SlClTtHr16qSfO2RFTU2NBgwYoPvvv1+SdMopp+i9997TggULNH78eIejc9bzzz+vJUuWaOnSperXr582b96s4uJi5eTkpHzfwJpDhw5p1KhRMgxDTz75pNPhOOrtt9/WvHnztGnTJvl8PqfDcZWamhpJ0ogRI3TzzTdLkk4++WS99tprWrBggc4991wnw3PUY489pjfeeEOrVq1S9+7dtW7dOk2ePFk5OTlxvZLKyKvDbrzxRr300ksqKSlRbm6u0+E47u2339Znn32mU089VWlpaUpLS9PatWv129/+VmlpaQoGg06H6Ijs7Gz17ds37NgJJ5yQ9CtbozF9+vTa0deTTjpJ48aN080338zIfR1dunSRJH366adhxz/99NPax1JZKHHduXOnVq9enfKjrmVlZfrss8/UrVu32s/inTt36te//rXy8/OdDs9RHTp0UFpaGp/JdXz33Xf6f//v/+mRRx7R8OHD9eMf/1g33nijRo8erYceeiiu34uRV4cYhqFf/epXWrlypUpLS9WjRw+nQ3KFwYMH69133w07NnHiRPXp00e33nqr/H6/Q5E56+yzz65XSu3DDz9U9+7dHYrIPb799lsddVT43+F+v792dASmHj16qEuXLlqzZo1OPvlkSVJVVZXefPNN/fKXv3Q2OIeFEtePPvpIJSUlat++vdMhOW7cuHH1RsqGDh2qcePGaeLEiQ5F5Q4tW7bU6aefzmdyHYcOHdKhQ4cS8nlM8uqQyZMna+nSpfrrX/+qNm3a1M45y8rKUkZGhsPROadNmzb15v22bt1a7du3T+n5wDfffLPOOuss3X///Ro1apQ2bNighQsXauHChU6H5rjhw4dr1qxZ6tatm/r166d33nlHjzzyiCZNmuR0aAlXXV2tbdu21d4vLy/X5s2b1a5dO3Xr1k3FxcW677771KtXL/Xo0UMzZsxQTk6OLrnkEueCToDG+iU7O1sjR47Upk2b9NJLLykYDNZ+Hrdr104tW7Z0KmzbNfXzUjeJb9Gihbp06aLjjz8+0aEmXFN9M336dI0ePVoDBw7UoEGD9I9//EMvvviiSktLnQs6AZrql3PPPVfTp09XRkaGunfvrrVr1+pPf/qTHnnkkfgGEtfaBYiapIi3p556yunQXIdSWaYXX3zROPHEE4309HSjT58+xsKFC50OyRWqqqqMKVOmGN26dTNatWplHHvsscYdd9xhHDhwwOnQEq6kpCTi58r48eMNwzDLZc2YMcPo3LmzkZ6ebgwePNjYunWrs0EnQGP9Ul5e3uDncUlJidOh26qpn5e6UqlUVjR9s2jRIuO4444zWrVqZfTv39944YUXnAs4QZrql7179xoTJkwwcnJyjFatWhnHH3+88fDDDxs1NTVxjcNnGCm4DQ0AAAA8iQVbAAAA8AySVwAAAHgGySsAAAA8g+QVAAAAnkHyCgAAAM8geQUAAIBnkLwCAADAM0heAQAA4BkkrwCQwnw+n1544QWnwwCAqJG8AkCCvP766/L7/Ro2bJil/5efn6+5c+faExQAeAzJKwAkyKJFi/SrX/1K69at0549e5wOBwA8ieQVABKgurpazz33nH75y19q2LBhevrpp8Mef/HFF3X66aerVatW6tChgy699FJJUmFhoXbu3Kmbb75ZPp9PPp9PkjRz5kydfPLJYeeYO3eu8vPza++/9dZb+ulPf6oOHTooKytL5557rjZt2mTn0wQA25G8AkACPP/88+rTp4+OP/54XXXVVfrjH/8owzAkSS+//LIuvfRS/exnP9M777yjNWvW6IwzzpAkBQIB5ebm6p577tHevXu1d+/eqL/nvn37NH78eK1fv15vvPGGevXqpZ/97Gfat2+fLc8RABIhzekAACAVLFq0SFdddZUk6YILLlBlZaXWrl2rwsJCzZo1S2PGjNHdd99d275///6SpHbt2snv96tNmzbq0qWLpe953nnnhd1fuHCh2rZtq7Vr1+qiiy5q5jMCAGcw8goANtu6das2bNigsWPHSpLS0tI0evRoLVq0SJK0efNmDR48OO7f99NPP9U111yjXr16KSsrS5mZmaqurtbHH38c9+8FAInCyCsA2GzRokU6fPiwcnJyao8ZhqH09HQ9/vjjysjIsHzOo446qnbaQcihQ4fC7o8fP15ffvml5s2bp+7duys9PV0/+clPdPDgwdieCAC4ACOvAGCjw4cP609/+pMefvhhbd68ufa2ZcsW5eTkaNmyZfrxj3+sNWvWNHiOli1bKhgMhh3r2LGjPvnkk7AEdvPmzWFt/ud//kc33XSTfvazn6lfv35KT0/XF198EdfnBwCJxsgrANjopZde0tdff61f/OIXysrKCnvssssu06JFi/Tggw9q8ODB6tmzp8aMGaPDhw/rb3/7m2699VZJZp3XdevWacyYMUpPT1eHDh1UWFiozz//XA888IBGjhypf/zjH/r73/+uzMzM2vP36tVLf/7znzVgwABVVVVp+vTpMY3yAoCbMPIKADZatGiRhgwZUi9xlczkdePGjWrXrp3+8pe/aNWqVTr55JN13nnnacOGDbXt7rnnHu3YsUM9e/ZUx44dJUknnHCCnnjiCc2fP1/9+/fXhg0bNG3atHrf++uvv9app56qcePG6aabblKnTp3sfcIAYDOfUXfSFAAAAOBSjLwCAADAM0heAQAA4BkkrwAAAPAMklcAAAB4BskrAAAAPIPkFQAAAJ5B8goAAADPIHkFAACAZ5C8AgAAwDNIXgEAAOAZJK8AAADwjP8PLU082OiyzYUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: average\n",
      "Features: ['school', 'Medu', 'Fedu', 'studytime', 'failures', 'higher', 'Dalc']\n",
      "The accuracy (R²) of the Model train is: 0.3405481626989806\n",
      "The accuracy (R²) of the Model test is: 0.19286294773182877\n",
      "The accuracy (MSE) of the train Model is: 5.51\n",
      "The accuracy (MSE) of the test Model is: 5.34\n",
      "The intercept (alpha) is: [9.64365135]\n",
      "The coefficients (betas) are: [[-0.99752934  0.44638903 -0.09165471  0.39739858 -1.32313728  1.74335354\n",
      "  -0.40721238]]\n",
      "The Standard Error (SE) is: 0.10055600716155957\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>higher</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Y_target</th>\n",
       "      <th>Y_predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.578184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>11.581466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15.666667</td>\n",
       "      <td>11.932713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.997476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>7.930985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>12.168501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>13.376836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>11.883928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>8.531352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.354076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school  Medu  Fedu  studytime  failures  higher  Dalc   Y_target  \\\n",
       "0         1     2     1          2         0       1     1   8.000000   \n",
       "1         0     0     2          3         0       1     2  14.333333   \n",
       "2         0     3     4          2         0       1     3  15.666667   \n",
       "3         1     2     3          1         0       1     1  10.000000   \n",
       "4         1     2     3          1         1       0     1   9.333333   \n",
       "..      ...   ...   ...        ...       ...     ...   ...        ...   \n",
       "125       0     2     1          2         0       1     2  14.000000   \n",
       "126       0     4     2          2         0       1     1  14.333333   \n",
       "127       1     2     2          3         0       1     1  15.333333   \n",
       "128       1     2     2          1         0       0     3  10.333333   \n",
       "129       0     2     1          2         0       1     4  10.000000   \n",
       "\n",
       "     Y_predicted  \n",
       "0      11.578184  \n",
       "1      11.581466  \n",
       "2      11.932713  \n",
       "3      10.997476  \n",
       "4       7.930985  \n",
       "..           ...  \n",
       "125    12.168501  \n",
       "126    13.376836  \n",
       "127    11.883928  \n",
       "128     8.531352  \n",
       "129    11.354076  \n",
       "\n",
       "[130 rows x 9 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linear regression for features contributing from correlation matrix pov\n",
    "linear_model_creator(df, Correlation_Relevant, 'average', test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***Hypothesis Testing***</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis Testing for further testing on the data set contributing to the target variable that we got from correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_test(betas, se):\n",
    "    # Calculate z-score\n",
    "    z_scores = np.array(betas) / np.array(se)\n",
    "    \n",
    "    # Calculate two-tailed p-values\n",
    "    p_values = 2 * (1 - norm.cdf(np.abs(z_scores)))\n",
    "    \n",
    "    # Determine significance based on p-value\n",
    "    significance = p_values < 0.1\n",
    "    \n",
    "    # Print significance message for each coefficient\n",
    "    for i, sig in enumerate(significance):\n",
    "        if sig:\n",
    "            print(f\"Beta {i+1} is significant (p-value < 0.1): z-score = {z_scores[i]}, p-value = {p_values[i]}\")\n",
    "    \n",
    "    return z_scores, p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta 1 is significant (p-value < 0.1): z-score = -9.920136729348322, p-value = 0.0\n",
      "Beta 2 is significant (p-value < 0.1): z-score = 4.439207985683078, p-value = 9.029053008369203e-06\n",
      "Beta 4 is significant (p-value < 0.1): z-score = 3.952012328428222, p-value = 7.749674705603837e-05\n",
      "Beta 5 is significant (p-value < 0.1): z-score = -13.158212197846767, p-value = 0.0\n",
      "Beta 6 is significant (p-value < 0.1): z-score = 17.337139661870413, p-value = 0.0\n",
      "Beta 7 is significant (p-value < 0.1): z-score = -4.049607691221739, p-value = 5.130356506621858e-05\n",
      "\n",
      "Z-scores and P-values:\n",
      "Beta 1: z-score = -9.920136729348322, p-value = 0.0\n",
      "Beta 2: z-score = 4.439207985683078, p-value = 9.029053008369203e-06\n",
      "Beta 3: z-score = -0.9114792103145246, p-value = 0.36204293472800764\n",
      "Beta 4: z-score = 3.952012328428222, p-value = 7.749674705603837e-05\n",
      "Beta 5: z-score = -13.158212197846767, p-value = 0.0\n",
      "Beta 6: z-score = 17.337139661870413, p-value = 0.0\n",
      "Beta 7: z-score = -4.049607691221739, p-value = 5.130356506621858e-05\n"
     ]
    }
   ],
   "source": [
    "#features contributing from correlation matrix pov\n",
    "betas = [-0.99752934, 0.44638903, -0.09165471, 0.39739858, -1.32313728, 1.74335354, -0.40721238]\n",
    "se = 0.10055600716155957\n",
    "\n",
    "# Perform z-test\n",
    "z_scores, p_values = z_test(betas, se)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nZ-scores and P-values:\")\n",
    "for i in range(len(betas)):\n",
    "    print(f\"Beta {i+1}: z-score = {z_scores[i]}, p-value = {p_values[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice from our hypothesis testing results that the features selected as contributing features are really contributing effectively to the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***Ridge Regression***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "selected_features=['school', 'Medu', 'Fedu', 'studytime', 'failures', 'higher', 'Dalc']\n",
    "X_features = df[selected_features]\n",
    "y = df['average']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def ridge_regression(X_features, y, Alpha):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the feature variables\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Train the Ridge Regression model\n",
    "    ridge_model = Ridge(alpha=Alpha)\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Predict on the testing set\n",
    "    y_pred = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    r2=r2_score(y_test, y_pred)\n",
    "    print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.837125117253835\n",
      "R2: 0.192488111396109\n"
     ]
    }
   ],
   "source": [
    "ridge_regression(X_features,y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.837071621778663\n",
      "R2: 0.19249442958269292\n"
     ]
    }
   ],
   "source": [
    "ridge_regression(X_features,y,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.832161677931082\n",
      "R2: 0.19307432799925006\n"
     ]
    }
   ],
   "source": [
    "ridge_regression(X_features,y,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.8151467057993225\n",
      "R2: 0.19508391419886295\n"
     ]
    }
   ],
   "source": [
    "ridge_regression(X_features,y,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"5\">***Polynomial Regression***</font><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X_features, y, Degree):\n",
    "    # Encode categorical features (e.g., 'school' and 'higher')\n",
    "    X_features = pd.get_dummies(X_features, drop_first=True)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Standardize the feature variables\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Generate polynomial features\n",
    "    poly = PolynomialFeatures(degree=Degree)\n",
    "    X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "    X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "    # Train the Polynomial Regression model (Linear Regression on polynomial features)\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "    # Predict on the testing set\n",
    "    y_pred = poly_model.predict(X_test_poly)\n",
    "\n",
    "    # Evaluate the model\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"R^2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 7.088476278843024\n",
      "R^2 Score: 0.1628017962099989\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression(X_features, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 12.131937995323767\n",
      "R^2 Score: -0.43286600654809804\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression(X_features, y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.949423765429014e+24\n",
      "R^2 Score: -1.0569890067538789e+24\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression(X_features, y, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 6.8371251172538345\n",
      "R^2 Score: 0.1924881113961091\n"
     ]
    }
   ],
   "source": [
    "polynomial_regression(X_features, y, 1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
